---
title:  "[CV] Scale-Invariant Feature Transform (SIFT)" 

categories:
  -  Vision
tags:
  - [CS]

toc: true
toc_sticky: true

date: 2022-10-20
last_modified_at: 2022-10-20
---

<br>

# 📹 Introduction to SIFT

![intro](https://user-images.githubusercontent.com/96368476/196869485-f829988f-e00f-4d64-9867-151ea3e71443.png){: width="60%" height="70%" .align-center}

<br>

![result](https://user-images.githubusercontent.com/96368476/196872462-ccbd8c6d-c272-44ac-996d-4fe595cf16fc.png){: width="60%" height="70%" .align-center}

SIFT는 key point를 찾아 descriptor를 붙이는 단계, descriptor를 이용해 원본 이미지와 변환 이미지의 key point를 매칭하는 단계, 총 두 단계로 이루어져 있다. SIFT로 뽑은 key point의 특징으로는 Scale, Rotation, Illumunation에 Invariant하다.

<br>

## Scaling Problem

| Original Image | Zoomed Image |
|:-:|:-:|
|![example1](https://user-images.githubusercontent.com/96368476/196873407-760393ae-9b6a-4a0d-819a-b329a9ace459.png)|![example2](https://user-images.githubusercontent.com/96368476/196873399-23f9a2ac-500d-4d52-ac18-4a676bc7ae0f.png)|

Harris Corner Detector에서 보았듯이 기존 detector는 같은 코너를 검출한다 하더라도 대상의 scale에 따라 다른 detector를 사용해야 했다. 실제 이미지에서 물체의 크기는 카메라로부터 얼마나 떨어져 있냐에 의존한다. 예를 들어 위 그림의 오른쪽 이미지는 왼쪽 이미지의 일부분을 확대한 것에 불과하다. 왼쪽 계단과 오른쪽 계단이 동일한 대상임에도 서로 다른 detector를 사용해야 이들을 탐지할 수 있다는 의미이다. <br>SIFT는 'Gaussian Pyramid'라는 기법으로 이를 멋지게 해결한다. ML의 object detection을 공부할 때 보았던 Spatial Pyramid Pooling 기법이랑 매우 유사한데 SIFT는 무려 2004년에 발표된 논문이다. Vision 분야도 정말 똑똑한 사람들이 많았구나 싶다.


<br>

## Algorithm

1. Detect Scale-Space Extrema
2. Accurate Key Point
3. Assign Orientation
4. Key Point Descriptor
5. Key Matching


<br>

# 📹 






<br>




[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}