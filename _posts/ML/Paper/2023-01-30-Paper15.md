---
title:  "[Paper Review] Deep Convolutional Generative Adversarial Networks (DCGANs)" 

categories:
  -  Paper
tags:
  - [ML, Generative]

toc: true
toc_sticky: true

date: 2023-01-30
last_modified_at: 2023-01-30
---

**Main Reference: <br>- [DCGANs Paper](https://github.com/inhopp/inhopp/files/10536727/DCGAN.pdf) <br>- [Jaejun Yoo's Playground](https://jaejunyoo.blogspot.com/2017/02/deep-convolutional-gan-dcgan-1.html)**
{: .notice--primary}

<br>


# 🚀 Introduction

GAN 모델은 maximum likelihood 기법을 사용하는 기존 생성모델들을 훌륭하게 대체했다. 하지만 학습이 불안정하고 generator가 이상한 output을 내뱉는 현상이 자주 발생하는 문제가 있었다. 본 논문에서는 multi-layer perceptron 구조로 이루어진 기존 Generator, Discriminator 모델을 Deep Convolution 기반 모델로 바꾸며 네트워크를 안정화시키는데 성공했고 추가적으로 다음 내용들을 다룬다.

- Convolution 구조를 사용하여 모델 안정화
- GAN에서 훈련된 Discriminator는 그 자체로 좋은 classifier임
- G, D의 filter들을 시각화하여 어떤 feature들을 학습하는지 확인
- Generator가 생성하는 이미지들은 마치 word2vec처럼 vector arithmetic 성질을 가짐



<br>


# 🚀 Approach and Model Architecture

사실 G, D를 convolution networks로 바꾸자는 아이디어는 너무 자연스러워 '논문감인가..?'하는 생각이 든다. 하지만 논문을 읽어보면 GAN을 scale up하는 과정이 상당히 어려웠다고 한다(어째서?). Facebook에서 근무하는 저자도 애를 좀 먹었는데 extensive model exploration 끝에 괜찮은 모델을 찾아냈다고 한다. 그렇게 나온 네트워크의 구조를 보면 단순 cnn 구조이다.

<br>

![dcgan1](https://user-images.githubusercontent.com/96368476/215671929-3d791633-c9d0-4c83-8519-037a38621a46.png){: width="60%" height="70%" .align-center}

- Pooling layer를 사용하지 않고
  - Discriminator에서는 strided convolution
  - Generator에서는 fractional-strided convolution (transposed conv)
- Batchnorm 사용 (오래된 모델이라 강조)
- 마지막 fully-connected layer를 제거
  - Global Average Pooling으로 교체했더니 수렴속도는 조금 느려지지만 안정성 향상
- Activation function 변경
  - Generator는 ReLU + 마지막 output 출력할 때에만 tanh
  - Discriminator는 LeakyReLU



<br>



# 🚀 Results

| Epoch 1 | Epoch 5 |
|:-:|:-:|
| ![dcgan2](https://user-images.githubusercontent.com/96368476/215682009-ff78460d-1ee8-411f-ad4f-78625d2978bd.png) | ![dcgan3](https://user-images.githubusercontent.com/96368476/215682081-33398152-edfc-4fbe-b666-69009c71bf29.png) |

- LSUN : bedrooms dataset (30000 training examples)
- G, D 모델을 scale up 하면서 overfitting & memorization이 걱정되었지만, 5 epoch을 돌려도 노이즈 낀 데이터가 존재
  - Underfitting이라 주장


<br>



# 🚀 Investigating and Visualizing The Internals of the Networks 

<br>

## Walking in the latent space

![dcgan5](https://user-images.githubusercontent.com/96368476/215689296-9768b426-4216-4bb9-919c-a5f07514ebc0.png){: width="60%" height="70%" .align-center}

오토인코더 모델의 경우 인코더를 통해 input 데이터를 저차원의 manifold(latent space)로 dimensionallity reduction을 수행한다. GAN의 경우 generator의 구조를 보면, 100차원의 noise vector z로 부터 새로운 이미지가 생성된다. 이 z 벡터를 부드럽게 움직이면 생성 이미지는 어떻게 변할까? 놀랍게도 생성 이미지 역시 부드럽게 변화한다. 즉, z 공간이 인코더 결과 나온 latent space와 비슷한 공간인 것처럼 작동한다. 예를 들어 그림의 마지막 행을 보면, TV가 자연스럽게 창문으로 변화한다.


<br>


## Visualizing the discriminator features

![dcgan6](https://user-images.githubusercontent.com/96368476/215691345-e0101a73-2b5b-4e84-9090-ffc333929393.png){: width="60%" height="70%" .align-center}

<br>

![dcgan4](https://user-images.githubusercontent.com/96368476/215682117-d19b4619-eac9-49ae-912b-5e3665df9403.png){: width="60%" height="70%" .align-center}

저자들은 Guided backpropagation기법을 이용해 Discriminator 내에 존재하는 filter들을 시각화했다. 그림의 왼쪽처럼 학습 전에는 각 filer가 어떤 feature들을 담당하는지 알기 어려운 반면 학습 후에는 각 filter가 특정 feature들을 담당함을 알 수 있다. 실제로도 imagenet 1k로 학습한 DCGAN의 discriminator 모델이 여느 모델에 꿀리지 않는 classifier역할을 한다.



<br>



# 🚀 Manipulating the Generator Representation

<br>

## Forgetting to draw certain objects

![dcgan7](https://user-images.githubusercontent.com/96368476/215693102-7f32e7c4-b65a-4837-aa76-6ca6511e532c.png){: .align-center}

동일한 방법으로 generator의 filter도 분석이 가능하다. 위 그림은 창문에 해당하는 filter를 꺼버렸을 때 나타나는 결과이다(첫 행: 수정 전, 아래 행: 수정 후). 창문이 문으로 바뀌는 등 재밌는 결과가 나타난다. 이러한 결과를 보고 있으면 자연스럽게 원하는 이미지를 생성하고싶은 욕구가 생긴다. 다음 논문으로 conditional GAN을 리뷰할 계획이다.


<br>


## Vector arithmetic on face samples

| Smiling man | Woman with glasses |
|:-:|:-:|
| ![dcgan8](https://user-images.githubusercontent.com/96368476/215696189-5a61fdbc-7f53-49e1-95dc-38eb1db2ab5a.png) | ![dcgan9](https://user-images.githubusercontent.com/96368476/215696182-81f61a38-0bec-4a35-9aeb-507424d1d335.png) |

Word2vec에서 단어는 마치 벡터처럼 작동한다. 예를 들어 **King(vec) - Man(vec) + Woman(vec) = Queen(vec)** 이 되는 것처럼 말이다. 이러한 현상이 DCGAN의 z 공간에서도 발생한다. 오른쪽 그림을 보면 **안경 쓴 남자 - 안경 안 쓴 남자 + 안경 안 쓴 여자 = 안경 쓴 여자** 가 나타남을 알 수 있다. 다만 모델이 불안정하기 때문에 몇 개의 벡터를 평균해야한다고 한다.

<br>

![dcgan10](https://user-images.githubusercontent.com/96368476/215696200-3b4815fb-e234-4b85-b0df-7aa53b3866df.png){: width="60%" height="70%" .align-center}

뿐만 아니라 왼쪽을 바라보는 얼굴을 생성하는 벡터, 오른쪽을 바라보는 얼굴을 생성하는 벡터의 평균 벡터는 가운데를 바라보는 얼굴을 생성한다! 정리를 마무리하며 드는 생각은 이 논문의 핵심이 단순한 모델의 구조가 아닌 GAN 특히 Generator의 무궁무진한 잠재력을 보인 것이라는 것이다.


<br>



# 🚀 Code

> 추가 예정



<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}