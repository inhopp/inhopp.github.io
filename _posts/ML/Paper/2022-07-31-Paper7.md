---
title:  "[논문 리뷰] Xception : Deep Learning with Depthwise Separable Convolutions" 

categories:
  -  Paper
tags:
  - [ML, Paper, Classification]

toc: true
toc_sticky: true

date: 2022-07-31
last_modified_at: 2022-07-31
---

**Paper: <br>- [Xception : Deep Learning with Depthwise Separable Convolutions](https://github.com/inhopp/inhopp/files/9228234/Xception.pdf)**
{: .notice--primary}


<br>

# 🚀 Abstract

| Simplified Inception | Reformulation Version | Extreme Version |
|:-:|:-:|:-:|
| ![1](https://user-images.githubusercontent.com/96368476/182015967-1b200631-b01d-4036-a08a-81ef77d0344e.png) | ![2](https://user-images.githubusercontent.com/96368476/182015968-15dc27e1-65ef-443b-ac67-964416fb0f93.png) | ![3](https://user-images.githubusercontent.com/96368476/182015969-6fc8d736-9406-404e-b444-cc2ca53300c6.png) |

저자들의 제시하는 inception module에 대한 해석은 simple convolution과 depthwise separable convolution의 중간 단계라는 것이다. 다시 말해 depthwise separable convolution module은 tower의 갯수가 매우 많은 inception module에 불과하다는 말이다(input channel을 얼마나 쪼갤 것인가의 차이). 이러한 관점에서 Inception V3의 다음 모델로 inception module을 depthwise separable module로 바꾼 모델을 생각할 수 있다. 저자들은 이 모델을 Extreme Inception, Xception 이라 이름 지었다. Xception은 Inception V3와 파라미터 갯수는 같으면서도 성능이 뛰어나다. 특히, 아주 큰 dataset에서는 그 차이가 더 벌어진다. 두 모델의 파라미터 갯수가 같기 때문에 성능의 차이는 모델의 크기에서 오는 것이 아닌, 얼마나 효율적으로 구성했느냐의 차이에서 오는 것이다. Depthwise Separable module이 왜 효율적으로 작동하는지 알아보자.


<br>


# 🚀 Introduction

## Inception Hypothesis

![6](https://user-images.githubusercontent.com/96368476/182018023-37a1691a-f1a8-4460-b434-b205e102d063.png){: width="50%" height="60%" .align-center}

Simple Convolution 연산을 생각해보자. convolution layer의 역할은 3D kernel로 channel별 feature, 2D spatial feature를 학습하는 것이다. 즉 하나의 커널이 spatial correlation, cross-channel correlation 두 가지 요인을 학습한다. **<span style="color:red">Inception module의 hypothesis(main idea)는 이 두 factor를 동시에 학습하는 것보다, 분리해서 학습하는 것이 더 효율적이라는 것이다.</span>** Inception은 먼저 cross-channel correlation을 구하고, 채널이 줄어든 공간에서 2d spatial correlation을 학습한다. 위에서 보았던 그림을 다시 보며 inception module의 철학을 살펴보자.

<br>


| Simplified Inception | Reformulation Version | Extreme Version |
|:-:|:-:|:-:|
| ![1](https://user-images.githubusercontent.com/96368476/182015967-1b200631-b01d-4036-a08a-81ef77d0344e.png) | ![2](https://user-images.githubusercontent.com/96368476/182015968-15dc27e1-65ef-443b-ac67-964416fb0f93.png) | ![3](https://user-images.githubusercontent.com/96368476/182015969-6fc8d736-9406-404e-b444-cc2ca53300c6.png) |

- 1by1 convolution을 따로 해야 할 필요가 있나? (simple -> reformulate)
- 1by1 convolution의 output channel을 가지고 2d spatial feature를 학습해야 하는데, 얼마나 많은 kernel이 필요하나?
- Extreme version : input channel의 갯수만큼 해주자 (reformulate -> extreme)

Extreme 버전 기저에 깔려있는 생각은 mush stronger hypothesis이다. 즉, "cross-channel correlation과 2d spatial correlation이 완전히 분리 가능하다"라는 가정인 것이다. 이 아이디어는 기존에 존재하던 depthwise separable convolution의 철학과 아주 유사하다. Inception의 철학을 따라가다 보면 depthwise separable이 자연스럽게 등장한다는 의미인데 굉장히 흥미로웠다. 둘 사이의 미묘한 차이점을 살펴보자.


<br>


## Extreme Inception vs Depthwise Separable

| Extreme Inception | Depthwise Separable |
|:-:|:-:|
| ![5](https://user-images.githubusercontent.com/96368476/182018022-e0e40e61-2f32-4458-b5d8-3ae0abf5bdee.png) | ![4](https://user-images.githubusercontent.com/96368476/182018020-3d6deb1f-822c-47ad-be54-e447998467d6.png) |

-  1️⃣ **연산의 순서가 다르다.**
  - inception의 경우 1by1 conv로 cross-channel correlation을 구한 뒤에 depthwise convolution을 수행한다.
  - depthwise separable의 경우 그 반대이다.
- 2️⃣ **첫 번째 연산 후 non-linearity (activation function)의 존재 여부**
  - inception의 경우 각각의 연산 후 모두 ReLU 연산이 수행된다.
  - depthwise separable의 경우 중간 단계에서는 activation function을 수행하지 않는다.

저자들은 1번 연산의 순서 차이가 stack setting에 불과할 뿐 중요하지 않다고 말한다. 나의 관점은 조금 다른데 마지막 dicussion에서 다루어 보자. 반면 2번 차이인 중간 non-linearlity의 존재 여부가 성능에 유의미한 영향을 끼침을 실험적으로 보여준다. 해당 실험의 내용은 뒤 Performance에서 다룬다.







<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}