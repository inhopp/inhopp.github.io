---
title:  "[논문 리뷰] Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)" 

categories:
  -  Paper
tags:
  - [ML, Paper]

toc: true
toc_sticky: true

date: 2022-02-17
last_modified_at: 2022-02-17
---

**Main Reference: <br>- [Deep Learning for Computer Vision](https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)** <br> 중간에 등장하는 ppt는 강의자료를 캡처한 것입니다.
{: .notice--warning}


**Paper: <br>- [Rich feature hierarchies for accurate object detection and semantic segmentation](https://github.com/inhopp/inhopp/files/8081058/RCNN.paper.pdf))**
{: .notice--primary}



<br>

# 🚀 Introduction

![1](https://user-images.githubusercontent.com/96368476/154297787-d69ddfd6-6e34-4b5e-a361-af5149b909bf.png){: width="60%" height="70%" .align-center}

오늘 소개할 R-CNN 논문은 딥러닝을 이용한 최초의 Object Detection 알고리즘이라 할 수 있다. 물론 비슷한 시도는 있었지만, 완성도 측면에서 첫 시도라 할 수 있겠다. 최근 사용되는 Object Detection & Semantic Sementation 기법을 이해하기 위해서 R-CNN의 내용은 필수적으로 알아야 한다.


<br>

# 🚀 Object Detection은 왜 어려울까?

본 논문은 출시된 2014년의 상황을 상상해보자. 2012년 딥러닝을 이용한 image classification 모델인 AlexNet이 등장하면서 사람들은 image classification에 대해서는 자신감을 얻었을 것이다. 그 후 자연스럽게 classification의 다음 단계인 object detection 분야에 눈독 들였을 것이다. 하지만 조금만 생각해봐도 object detection 모델은 훨씬 까다롭다는 것을 알 수 있다. 저자들 역시 어떻게 해야 CNN을 활용할 수 있을지 가장 중요하게 고민했다고 한다.
<br>

![2](https://user-images.githubusercontent.com/96368476/154305212-c72d9dd9-c60d-4936-b694-501b8970d4a5.png){: width="50%" height="60%" .align-center}

- **Input** : 하나의 RGB Image
- **Multiple Output** : 몇 개의 object가 존재하는 지는 이미지마다 다르다
- **Multiple types of output** : 하나의 object마다 어떤 카테고리에 속하는지(what), 어디에 있는지(where) 즉, 다른 타입의 output이 필요하다.
- **Large Image** : object detection은 기본적으로 높은 해상도가 요구된다.

<br>

## Sliding Window

![3](https://user-images.githubusercontent.com/96368476/154308021-72c2d46a-b8b8-40ed-a523-07fc51cfce59.png){: width="80%" height="90%" .align-center}

가장 먼저 떠오르는 방법은 고정시킨 bounding box를 sliding 하면서 detection 하는 방법일 것이다. 하지만 가능한 bounding box의 모양, bouding box의 위치를 고려하면 눈앞이 캄캄해진다. 본 논문에서 대안으로 사용한 방법은 Region Proposal 방법이다. 여담으로 R-CNN이 나오기 직전 CNN을 활용한 **Overfeat Detection** 모델은 sliding window를 이용한 방법이다(말만 sliding window. 기막힌 테크닉들 많음). 논문에서 우리가 만든 R-CNN이 overfeat 보다 좋다고 계속 부관참시하더라.


<br>

# 🚀 Region Proposal

![4](https://user-images.githubusercontent.com/96368476/154305238-3d65a001-2c85-4004-8179-22f66e808796.png){: width="60%" height="70%" .align-center}

Region Proposal은 object가 있을 만한 위치 후보군을 제시해주는 모델이다. 이는 기존의 Computer Vision 분야에서도 논문이 우수수 쏟아지는 뜨거운 주제였는데 생태계 파괴 종 딥러닝의 등장 이후 모든 알고리즘은 씹어 먹혔다고 한다. (딥러닝 엔딩..) 아무튼 본 논문에서 사용한 Region Proposal 알고리즘인 Selective Search에 대해 알아보자.

<br>

## Selective Search

**상상 속 selective search**

![5](https://user-images.githubusercontent.com/96368476/154314768-a47129e9-3508-4165-b842-55d8ffc3e349.png){: width="80%" height="90%" .align-center}

Selective Search의 골자는 Color, Texture, Size, Fill 이렇게 4가지 구성 요소로 주변 영역들과의 Similarity를 계산한다. 그 후 similarity가 비슷한 영역들을 merge해 나가면서 최후에 남는 영역들을 제안해주는 알고리즘이다. 하지만 최후에 남는 영역들을 제안받으면 놓치는 object 들이 너무 많아서 본 논문에서는 2천 개의 후보 영역을 제안받는다.

<br>

**현실**

![6](https://user-images.githubusercontent.com/96368476/154314775-135b9caf-5a10-45d4-8644-a255c56f4cda.png){: width="70%" height="80%" .align-center}

그래도 2천 개의 영역을 cpu로 몇 초안에 계산해 내는 훌륭한 알고리즘이다. Selective Search의 가장 큰 문제는 같은 object를 몇 픽셀 차이로 여러 번 제안한다는 것이다. 따라서 중복된 box를 제거하는 방법이 필요한데 이 때 사용되는 개념이 IoU, NMS 이다.


<br>

## IoU - Intersection over Union

![7](https://user-images.githubusercontent.com/96368476/154318915-63b70d79-701a-4dc7-ae97-a370fc4f2668.png){: width="50%" height="60%" .align-center}

우리의 전략은 실제 bounding box인 Ground-Truth box와 가장 가까운 box를 빼고 전부 치워버리는 것이다. 그려려면 두 box가 서로 가깝다는 것이 어떤 의미인지를 정해야 하는데 그 때 사용하는 기준이 바로 **IoU** 이다.

<br>

![8](https://user-images.githubusercontent.com/96368476/154318916-1c716636-247b-4746-a078-d765c9313b18.png)

- IoU > 0.5 : 음 그럭저럭 잘 맞네
- IoU > 0.7 : 아주 좋아
- IoU > 0.9 : 완벽해! (실제로는 pixel 몇 개 차이)

이제 box-metric을 정의했으니, Non-Max Suppression(NMS) 알고리즘을 이해할 수 있다. NMS는 말 그대로 max값 빼고 전부 압축시키겠다는 의미이다.

<br>

## NMS - Non Max Suppression

![9](https://user-images.githubusercontent.com/96368476/154318918-d9c90def-0634-4041-88a0-1a85cbe88cf4.png){: width="50%" height="60%" .align-center}

1. 가장 점수가 높은 box 선택
2. IoU > threshold (ex 0.7) 인 box들 전부 제거
   - threshold 값은 hyper parameter
3. 다시 1번으로 (남는 box가 없을 때까지)

<br>

![10](https://user-images.githubusercontent.com/96368476/154318900-472a718d-aef7-4711-a590-1f486b2fe073.png){: width="80%" height="90%" .align-center}


<br>

## NMS 한계

![11](https://user-images.githubusercontent.com/96368476/154318912-e8697b16-3e19-4595-9e0d-23198cfb3de8.png){: width="50%" height="60%" .align-center}

- NMS는 Object Detection 분야에서 반드시 필요한 좋은 알고리즘이다.
- 하지만 object들이 highly overlapping되면 **<span style="color:red">실제 필요한 box들도 지우게 된다.</span>**
- 이는 Object Detection 분야의 Open Problem 이라고 한다.




<br>

# 🚀 R-CNN Network Architectures

![12](https://user-images.githubusercontent.com/96368476/154326345-cfe23237-23ec-469f-a013-cbc7dac9e0cf.jpg){: width="80%" height="90%" .align-center}
![13](https://user-images.githubusercontent.com/96368476/154328988-f25553c5-a7a0-43d9-a022-f3967432175f.jpg){: width="80%" height="90%" .align-center}

- Input Image 입력
- selective search로 RoI(Region of Interst) 제안
- RoI warping - CNN 모델의 input size 맞춰주기 (ex. 224x224)
- 각 영역에 대하여 convolution (shared weights)
- convolution 후 얻은 feature vector로 
  - classification
  - bounding box regression







<br>


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}