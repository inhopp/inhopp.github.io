---
title:  "[논문 리뷰] Rich feature hierarchies for accurate object detection and semantic segmentation (R-CNN)" 

categories:
  -  Paper
tags:
  - [ML, Paper]

toc: true
toc_sticky: true

date: 2022-02-17
last_modified_at: 2022-02-17
---

**Main Reference: <br>- [Deep Learning for Computer Vision](https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r)** 
{: .notice--warning}


**Paper: <br>- [Rich feature hierarchies for accurate object detection and semantic segmentation](https://github.com/inhopp/inhopp/files/8081058/RCNN.paper.pdf))**
{: .notice--primary}



<br>

# 🚀 Introduction

![1](https://user-images.githubusercontent.com/96368476/154297787-d69ddfd6-6e34-4b5e-a361-af5149b909bf.png){: width="60%" height="70%" .align-center}

오늘 소개할 R-CNN 논문은 딥러닝을 이용한 최초의 Object Detection 알고리즘이라 할 수 있다. 물론 비슷한 시도는 있었지만, 완성도 측면에서 첫 시도라 할 수 있겠다. 최근 사용되는 Object Detection & Semantic Sementation 기법을 이해하기 위해서 R-CNN의 내용은 필수적으로 알아야 한다.


<br>

# 🚀 Object Detection은 왜 어려울까?

본 논문은 출시된 2014년의 상황을 상상해보자. 2012년 딥러닝을 이용한 image classification 모델인 AlexNet이 등장하면서 사람들은 image classification에 대해서는 자신감을 얻었을 것이다. 그 후 자연스럽게 classification의 다음 단계인 object detection 분야에 눈독 들였을 것이다. 하지만 조금만 생각해봐도 object detection 모델은 훨씬 까다롭다는 것을 알 수 있다. 저자들 역시 어떻게 해야 CNN을 활용할 수 있을지 가장 중요하게 고민했다고 한다.
<br>

![2](https://user-images.githubusercontent.com/96368476/154305212-c72d9dd9-c60d-4936-b694-501b8970d4a5.png){: width="50%" height="60%" .align-center}

- **Input** : 하나의 RGB Image
- **Multiple Output** : 몇 개의 object가 존재하는 지는 이미지마다 다르다
- **Multiple types of output** : 하나의 object마다 어떤 카테고리에 속하는지(what), 어디에 있는지(where) 즉, 다른 타입의 output이 필요하다.
- **Large Image** : object detection은 기본적으로 높은 해상도가 요구된다.

<br>

## Sliding Window

![3](https://user-images.githubusercontent.com/96368476/154308021-72c2d46a-b8b8-40ed-a523-07fc51cfce59.png){: width="80%" height="90%" .align-center}

가장 먼저 떠오르는 방법은 고정시킨 bounding box를 sliding 하면서 detection 하는 방법일 것이다. 하지만 가능한 bounding box의 모양, bouding box의 위치를 고려하면 눈앞이 캄캄해진다. 본 논문에서 대안으로 사용한 방법은 Region Proposal 방법이다. 여담으로 R-CNN이 나오기 직전 CNN을 활용한 **Overfeat Detection** 모델은 sliding window를 이용한 방법이다(말만 sliding window. 기막힌 테크닉들 많음). 논문에서 우리가 만든 R-CNN이 overfeat 보다 좋다고 계속 부관참시하더라.


<br>

# 🚀 Region Proposal

![4](https://user-images.githubusercontent.com/96368476/154305238-3d65a001-2c85-4004-8179-22f66e808796.png){: width="60%" height="70%" .align-center}

Region Proposal은 object가 있을 만한 위치 후보군을 제시해주는 모델이다. 이는 기존의 Computer Vision 분야에서도 논문이 우수수 쏟아지는 뜨거운 주제였는데 생태계 파괴 종 딥러닝의 등장 이후 모든 알고리즘은 씹어 먹혔다고 한다. (딥러닝 엔딩..) 아무튼 본 논문에서 사용한 Region Proposal 알고리즘인 Selective Search에 대해 알아보자.

<br>

## Selective Search

**상상 속 selective search**

![5](https://user-images.githubusercontent.com/96368476/154314768-a47129e9-3508-4165-b842-55d8ffc3e349.png){: width="80%" height="90%" .align-center}

Selective Search의 골자는 Color, Texture, Size, Fill 이렇게 4가지 구성 요소로 주변 영역들과의 Similarity를 계산한다. 그 후 similarity가 비슷한 영역들을 merge해 나가면서 최후에 남는 영역들을 제안해주는 알고리즘이다. 하지만 최후에 남는 영역들을 제안받으면 놓치는 object 들이 너무 많아서 본 논문에서는 2천 개의 후보 영역을 제안받는다.

<br>

**현실**

![6](https://user-images.githubusercontent.com/96368476/154314775-135b9caf-5a10-45d4-8644-a255c56f4cda.png){: width="70%" height="80%" .align-center}

그래도 2천 개의 영역을 cpu로 몇 초안에 계산해 내는 훌륭한 알고리즘이다. Selective Search의 가장 큰 문제는 같은 object를 몇 픽셀 차이로 여러 번 제안한다는 것이다. 따라서 중복된 box를 제거하는 방법이 필요한데 이 때 사용되는 개념이 IoU, NMS 이다.


<br>

## IoU - Intersection over Union

![7](https://user-images.githubusercontent.com/96368476/154318915-63b70d79-701a-4dc7-ae97-a370fc4f2668.png){: width="50%" height="60%" .align-center}







<br>


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}