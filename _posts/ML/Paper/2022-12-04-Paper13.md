---
title:  "[ë…¼ë¬¸ ë¦¬ë·°] U-Net: Convolutional Networks for Biomedical Image Segmentation (+ FCN)" 

categories:
  -  Paper
tags:
  - [ML, Segmentation]

toc: true
toc_sticky: true

date: 2022-12-04
last_modified_at: 2022-12-04
---

**Main Reference: <br>- [FCN Paper](https://github.com/inhopp/inhopp/files/10148049/FCN.pdf) <br>- [U-Net Paper](https://github.com/inhopp/inhopp/files/10146872/UNET.pdf) <br>- https://89douner.tistory.com/297**
{: .notice--primary}


<br>

# ğŸš€ Introduction

2015ë…„ì— ë“±ì¥í•œ Fully Convolutional Networks(FCN)ì€ CNNê¸°ë°˜ segmentation ëª¨ë¸ì˜ ì´ˆê¸° ë²„ì „ì´ë‹¤. ì˜¤ëŠ˜ ì´ì•¼ê¸°í•  U-Net ì—­ì‹œ 2015ë…„ì— ë“±ì¥í–ˆìœ¼ë©° FCNì„ ê°œëŸ‰í•œ ëª¨ë¸ì´ë‹¤. U-Netê³¼ FCNì˜ êµ¬ì¡°ê°€ ë§¤ìš° ë¹„ìŠ·í•˜ë‹¤ê³  ëŠê»´ì§€ê¸° ë•Œë¬¸ì— FCNì˜ ë‚´ìš©ì€ ë³¸ í¬ìŠ¤íŒ…ì—ì„œ ì ê¹ ì†Œê°œí•˜ëŠ” ê²ƒìœ¼ë¡œ ë„˜ì–´ê°€ë ¤ í•œë‹¤. ë˜ í•˜ë‚˜ ì¸ìƒì ì´ì—ˆë˜ ê²ƒì€ ì˜ë£Œ ì´ë¯¸ì§€ ë°ì´í„°ì— ê´€í•œ ë‚´ìš©ì´ë‹¤. ë³¸ ë…¼ë¬¸ì„ í¬í•¨í•œ ë§ì€ ë…¼ë¬¸ì˜ ì œëª©ì—ì„œ 'biomedical image ì–´ì©Œêµ¬' ë¼ëŠ” ê²ƒì„ ê°•ì¡°í•œë‹¤. U-Netì˜ ë…¼ë¬¸ì„ ì½ì–´ë³´ë©° ì•Œê²Œ ëœ ê²ƒì€ biomedical imageì´ê¸° ë•Œë¬¸ì— ê°€ëŠ¥í•œ data augmentationì´ ì¡´ì¬í•œë‹¤ëŠ” ê²ƒì´ë‹¤. Segmentationì´ë©´ ê·¸ëƒ¥ segmentationì´ì§€ ì™œ ì˜ë£Œ ì´ë¯¸ì§€ë¼ëŠ” ì‚¬ì¡±ì„ ë‹¬ê¹Œ ì‹¶ì—ˆëŠ”ë°, ì¡°ê¸ˆì´ë‚˜ë§ˆ ì´ìœ ë¥¼ ì•Œ ê²ƒ ê°™ë‹¤.



<br>

# ğŸš€ About Fully Convolutional Networks(FCN)

![fcn](https://user-images.githubusercontent.com/96368476/205480099-1eb11fbd-af2a-445e-b617-0a287ce6898b.png){: width="70%" height="80%" .align-center}

FCNì˜ êµ¬ì¡°ì—ëŠ” í¬ê²Œ 3ê°€ì§€ íŠ¹ì„±ì´ ì¡´ì¬í•œë‹¤.
 - Can take arbitrary size as input
 - Upsampling
 - Skip connection

<br>

## Can take arbitrary size as input

ë§Œì•½ ëˆ„êµ°ê°€ segmentation ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤ë©´ ê°€ì¥ ë¨¼ì € ë“œëŠ” ìƒê°ì€ 'ë¼ë²¨ë§ ëœ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ êµ¬í•˜ì§€?' ì¼ ê²ƒì´ë‹¤. Segmentation taskì˜ íŠ¹ì„±ìƒ í”½ì…€ ë‹¨ìœ„ë¡œ ë¼ë²¨ë§ì„ í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ë§Œë“¤ê¸°ê°€ ë§¤ìš° ì–´ë µë‹¤. Input sizeê°€ ì¡°ê¸ˆ ë‹¤ë¥´ë‹¤ê³  ë‚˜ë§Œì˜ ì‘ê³  ì†Œì¤‘í•œ ë°ì´í„°ë¥¼ ë²„ë ¤ì„œ ë˜ê² ëŠ”ê°€. ì´ëŸ¬í•œ ë¬¸ì œ ë•Œë¬¸ì— FCNì€ ê¸°ì¡´ CNNëª¨ë¸ì—ì„œ fully connected layerë¥¼ ì œê±°í–ˆë‹¤. CNNì—ì„œ fixed input sizeë¥¼ ìš”êµ¬í•˜ëŠ” ë²”ì¸ì´ ë°”ë¡œ fc layerì´ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ fc layerë¥¼ 1x1 conv layerë¡œ êµì²´í–ˆê³ , ì„ì˜ì˜ í¬ê¸°ë¥¼ ê°€ì§„ ë°ì´í„°ë¥¼ inputìœ¼ë¡œ ë°›ì„ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

<br>

## Upsampling

| Convolution | Transposed Convolution |
|:-:|:-:|
| ![upsample1](https://user-images.githubusercontent.com/96368476/205480844-38bd17c1-3c5a-4380-8073-db24af74111a.png) | ![upsample2](https://user-images.githubusercontent.com/96368476/205480851-758c23e4-e829-4597-aaed-c29f099ebb31.png) |

Segmenationì˜ ë˜ í•˜ë‚˜ì˜ íŠ¹ì§•ì€ output dataê°€ ë‹¨ìˆœ í´ë˜ìŠ¤ê°€ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ë‹¤. Input ë°ì´í„°ì˜ ë™ì¼í•œ í¬ê¸°ì˜ sizeê°€ ìš”êµ¬ë˜ë©° í”½ì…€ ë‹¨ìœ„ë¡œ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ ì•ë‹¨ conv layerë“¤ì„ í†µí•´ ì–´ë–¤ objectë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€(context)ë¥¼ íŒŒì•…í•˜ê³ , input sizeì™€ ë™ì¼í•œ output sizeë¥¼ ì–»ê¸° ìœ„í•´ upsampling ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. Umsampling ê³¼ì •ì—ëŠ” í¬ê²Œ ë‘ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬í•œë‹¤. ì²«ì§¸ëŠ” non-trainableí•œ ë‹¨ìˆœ max-pooling, average-poolingì˜ ì—­ì—°ì‚° ê³¼ì •ì´ê³ , ë‘˜ì§¸ëŠ” trainableí•œ transposed convolution ê³¼ì •ì´ë‹¤. FCNì—ì„œëŠ” í•™ìŠµ ê°€ëŠ¥í•œ transposed convolution ì—°ì‚°ì„ í†µí•´ upsamplingì„ ìˆ˜í–‰í•œë‹¤. <br>'Poolingì˜ ì—­ì—°ì‚°ì„ ì´ì•¼ê¸°í•˜ëŠ”ë° ì™œ conv layerê°€ ë“±ì¥í•˜ì§€?' ì‹¶ì„ ìˆ˜ ìˆëŠ”ë° paddingì´ ì—†ëŠ” convolutionì€ down-samplingì´ê¸° ë•Œë¬¸ì´ë‹¤. ì´ì œ transposed-convolutionì´ ë¬´ì—‡ì¸ì§€ ì´ì•¼ê¸°í•´ë³´ì. ê¸°ì¡´ì˜ convolution ê³¼ì •ì„ matrix ê³±ìœ¼ë¡œ í‘œí˜„í•œë‹¤ë©´ ì™¼ìª½ ê·¸ë¦¼ì²˜ëŸ¼ Ax=y í˜•íƒœë¡œ í‘œí˜„ ê°€ëŠ¥í•˜ë‹¤. ì´ë•Œ y(2x2)ë¥¼ í†µí•´ x(3x3)ë¥¼ ì–»ê³  ì‹¶ë‹¤ë©´, A ëŒ€ì‹  A-transpose í˜•íƒœë¥¼ ê³±í•´ì£¼ë©´ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. (A * x = y  &  A^T * y = x)


<br>

## Skip connection

![fcn_result](https://user-images.githubusercontent.com/96368476/205481717-09285681-d0d1-4dd4-8668-4d478709d6b2.png){: width="50%" height="60%" .align-center}

ë§ˆì§€ë§‰ìœ¼ë¡œ skip connection íŒŒíŠ¸ì´ë‹¤. FCNì€ conv layerë¥¼ í†µí•´ ì´ë¯¸ì§€ì˜ ì–´ë–¤ objectë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ ì•Œì•„ë‚´ê³ , Upsamplingì„ í†µí•´ objectê°€ ì–´ë””ì— ìˆëŠ”ì§€ íŒŒì•…í•´ì•¼ í•œë‹¤. í•˜ì§€ë§Œ ì•ë‹¨ conv layerë¥¼ í†µê³¼í•˜ë©´ objectì˜ ìœ„ì¹˜ ì •ë³´ì˜ ìƒë‹¹ ë¶€ë¶„ì„ ì†ì‹¤í•˜ê²Œ ëœë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ conv layerì˜ ì¤‘ê°„ì¤‘ê°„ outputì„ ê°€ì ¸ì™€ upsampling ê³¼ì •ì—ì„œ ë”í•´ì£¼ê²Œ ëœë‹¤. ì „í˜•ì ì¸ spatial pyramid êµ¬ì¡°ì´ë‹¤. ìœ„ ê·¸ë¦¼ì€ ê°€ì¥ ì™¼ìª½ë¶€í„° skip connectionì„ ì´ìš©í•˜ì§€ ì•Šì€ ê²½ìš°, 16 strideë§ˆë‹¤, 8 strideë§ˆë‹¤ skip connectionì„ ì‚¬ìš©í•œ ê²½ìš°ì´ë‹¤. ê°€ì¥ ì´ˆê¸° ëª¨ë¸ì´ë¼ ê·¸ëŸ°ì§€ ì„±ëŠ¥ì´ ì¢‹ì§€ ëª»í•˜ë‹¤.






<br>


# ğŸš€ Code

**[U-Net from scratch (pytorch)](https://github.com/inhopp/UNet)**
{: .notice--primary}

![inference](https://user-images.githubusercontent.com/96368476/204140350-ba77117f-8bd0-4c5d-91cb-9ffbfc5df0af.png){: width="70%" height="80%" .align-center}


<br>
<br>



[ë§¨ ìœ„ë¡œ ì´ë™í•˜ê¸°](#){: .btn .btn--primary }{: .align-right}