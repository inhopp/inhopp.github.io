---
title:  "[논문 리뷰] You Only Look Once: Unified, Real-Time Object Detection (YOLO)" 

categories:
  -  Paper
tags:
  - [ML, Object Detection]

toc: true
toc_sticky: true

date: 2022-10-11
last_modified_at: 2022-10-11
---

**Paper: <br>- [You Only Look Once: Unified, Real-Time Object Detection (YOLO)](https://github.com/inhopp/inhopp/files/9751618/yolo_v1.pdf)**
{: .notice--primary}


<br>

# 🚀 Abstract

![test](https://user-images.githubusercontent.com/96368476/195012907-6d0ff077-7692-4929-bb14-bdd658a197cd.png){: width="60%" height="70%" .align-center}

지금까지 Detection 작업은 Multi-task problem이었다. Faster R-CNN을 예로 들어보자. 먼저 Region Proposal Networks를 통해 object가 있을 법한 영역을 제안하고 그 위에서 bbox regression & classify 작업을 진행했다. 더욱이 모델 훈련에서는 두 네트워크를 분리하여 fine tuning을 진행해야 하는 등 전체 모델이 복잡한 pipeline을 구성한다. 오늘 소개하는 YOLO 모델은 복잡한 multi-task problem을 하나의 regression problem으로 만들었다. 즉, 기존의 방식처럼 rpn이 제안하는 영역을 기다렸다가 수많은 영역들을 보아야 하는 것이 아니라 전체 이미지를 한 번 보는 것만으로 충분하다는 것이다. 따라서 모델의 inference speed가 많이 빨라졌는데 기본적으로 45fps, 모델을 작게 만든 fast yolo의 경우 155fps를 달성했다. 분명 faster rcnn (5fps) 공부할 때 real-time 모델이라고 배웠는데, 본 논문에서는 5fps가 무슨 real time이냐며 급 나누기를 시전한다. CVPR 2016에서 저자가 직접 real-time detection을 시연하는 영상이 남아있는데 지금 봐도 굉장히 멋지다.


<br>


# 🚀 Introduction

### Faster RCNN Architecture
![architecture](https://user-images.githubusercontent.com/96368476/190898741-a73d296a-c5c4-4d28-95ed-11e09d5501e6.png){: width="60%" height="70%" .align-center}

기존의 Detection 모델, Faster RCNN은 먼저 region proposal을 통해 bounding box를 생성하고 생성된 box에 대해 classification 작업을 수행하는 multi-task 방식이다. 이런 복잡한 방식은 inference 속도가 느리고, 무엇보다 독립적인 네트워크가 따로 훈련하기 때문에 최적화가 매우 까다롭다.

<br>

### YOLO Architecutre

![architecture](https://user-images.githubusercontent.com/96368476/195017645-36272d54-36a3-4496-aa6f-adb0dd530b8d.png){: width="60%" height="70%" .align-center}

반면 YOLO 모델은 하나의 이미지 픽셀로부터 bbox, class porb를 예측하는 single regression problem 구조를  이룬다. 이처럼 원본 이미지 전체를 input으로 받으며, 바로 최적화가 가능하다는 등 여러 장점이 존재한다. YOLO의 장점을 좀 더 자세히 설명하면 다음과 같다.

- YOLO는 complex pipeline이 아닌 single regression problem 구조를 가지기 때문에 매우 빠르다.
    - Experiments 파트에 나오지만 실질적인 real-time 모델 중 성능이 압도적이다.
- 제안된 특정 영역이 아닌 이미지 전체를 global하게 보고 classify 한다.
    - 즉 객체뿐만 아니라 주변 정보도 같이 학습한다는 의미이다.
    - Faster RCNN에 비해 back-ground error가 절반 이하로 줄어든다.
- YOLO는 조금 더 일반화된 표현을 학습할 수 있다.
    - 위와 비슷한 맥락으로 주변 정보도 함께 학습하기 때문에, 학습 과정에 등장하지 않은 데이터가 들어와도 유연하게 대응한다.


하지만 YOLO도 완벽하지는 않다. 뒤에서 살펴보겠지만 구조적인 문제로 작은 객체를 탐지하는데 어려움을 겪는다. 또한 속도에 큰 비중을 두어서 다른 detection model들에 비해 mAP가 떨어지는 편이다.

<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}