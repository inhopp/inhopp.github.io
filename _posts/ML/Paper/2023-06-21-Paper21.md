---
title:  "[Paper Review] StyleGAN : A Style-Based Generator Architecture for Generative Adversarial Networks" 

categories:
  -  Paper
tags:
  - [ML, Generative]

toc: true
toc_sticky: true

date: 2023-06-21
last_modified_at: 2023-06-21
---

**Main Reference: <br>- [StyleGAN Paper](https://arxiv.org/abs/1812.04948)**
{: .notice--primary}



<br>


# 🚀 Introduction

GAN의 이미지 합성 과정을 이해하기 위한 많은 노력이 있었으나 여전히 black box처럼 작동한다는 비판이 존재한다. Latent Space에 대한 이해가 아직 부족하고, stochastic한 feature들을 컨트롤하는데 어려움이 있다. 저자들은 style transfer모델에 영감을 받아 이미지 합성 과정을 control할 수 있는 새로운 generator 구조를 디자인했다. 

- Noise Input이 아닌, learned constant input (Disentanglemenmt)
- 각 conv layer 이후 latnent에 기반한 style 추가
- noise를 주입함으로써 stochastic variation 추가

이러한 구조를 바탕으로 discriminator나 loss function의 변화 없이 큰 성능 향상을 이루었다. 뿐만 아니라 latent space의 disentanglement를 평가하는 지표를 제안하고, 고화질의 얼굴 데이터셋 FFHQ를 배포했다.


<br>


# 🚀 Style-Based Generator

![1](https://github.com/inhopp/inhopp/assets/96368476/d4556027-d672-46cf-aaa1-c6ff8f5ed86f){: width="70%" height="80%" .align-center}

일반적인 GAN은 latent code가 바로 generator의 input으로 들어갔다. 본 논문에서 제안한 방법은 latent space input z가 non-linear mapping f를 거처 w를 생성한다. 이때 mapping f는 8개의 MLP-layer로 구성되어 있고, z와 w의 차원은 모두 512이다. Multiple-discriminator, attention 등 dicriminator의 성능을 향상시키거나 generator의 구조를 바꾸기 위해 많은 연구가 진행되었는데 StyleGAN은 비교적 단순한 input의 embedding 부분만을 수정함으로써 많은 성과를 얻을 수 있었다.

- Base model은 고해상도의 이미지를 생성할 수 있는 PGGAN 사용
- 각 conv layer 이후 AdaIN 연산으로 style 합성
- 각 conv layer 이후 noise 주입 

<br>

![2](https://github.com/inhopp/inhopp/assets/96368476/35c996f6-6928-453d-b4de-6a2707095554){: width="70%" height="80%" .align-center}

- 각 method를 추가하면서 구한 FID-score



<br>



# 🚀 Properties of the Style-Based Generator

## Style Mixing

Style들을 localize하기 위해 mixing regulization을 도입했다. 하나가 아닌 두 개의 random latent code를 사용한다. Crossover 시점을 지정하고, 해당 시점 이전에는 w_1 latent code, 이후에는 w_2 latent code를 이용하는 방식이다.

![3](https://github.com/inhopp/inhopp/assets/96368476/0134ac77-abfc-4db0-bc84-9b32633dc6d2){: width="70%" height="80%" .align-center}

- Coarse Style : 초반 낮은 해상도에 합성되는 style은 머리 스타일, 얼굴 모양, 안경 여부 등 전체적인 스타일에 영향을 미친다.
- Middle Style : 중간 해상도에는 눈을 감았는지 여부 등 애매한 스타일
- Fine Style : 높은 해상도에 합성되는 style에서는 헤어 색상이나 미세한 스타일 담당


<br>

## Stocahstic Variation

![4](https://github.com/inhopp/inhopp/assets/96368476/2451fba9-760d-4798-842d-55a34e183e70){: width="70%" height="80%" .align-center}

인물 사진에는 머리카락, 수염, 죽은깨, 피부 등 다양한 stochasitc한 요소들이 존재한다. 기존의 generator들은 단 하나의 input으로 부터 이미지를 합성하기 때문에 필요한 시점, 필요한 위치에 랜덤 값을 주기가 어려웠다. StyleGAN의 경우 각 conv layer 이후 per-pixel noise를 주입함으로써 이러한 문제를 피해갔다.

![5](https://github.com/inhopp/inhopp/assets/96368476/73c668b7-e01a-4d52-9fc9-f8c4a62593e5){: width="70%" height="80%" .align-center}

흥미로운 지점은 noise 또한 style과 마찬가지로 tight하게 localize 되어있다는 것이다. 

- (a) : 모든 layer에 noise 적용
- (b) : noise x
- (c) : fine layer에만 noise 적용 (이미지 합성 후반부)
- (d) : coarse layer에만 noise 적용 (이미지 합성 초반부)





<br>


# 🚀 Disentanglement Studies

![6](https://github.com/inhopp/inhopp/assets/96368476/e8759368-9ccb-4f55-aa3e-8fee37a5f5d5){: width="70%" height="80%" .align-center}

Disentanglement에 대한 정의는 여러 방법으로 할 수 있겠지만, 여기서는 latent space가 하나의 요소마다 linear한 부분 공간으로 구성되어 있는가를 뜻한다. 일반적으로  latent space에서 가우시안 분포로 뽑은 noise 벡터를 이용해 이미지를 합성하기 때문에 선형적인 구조를 갖기 어렵다. 하지만 StyleGAN의 경우 mapping function을 통한 intermediate latent space W로 부터 이미지를 합성한다. W space의 경우 특정 분포에 의한 제약이 없기 때문에 선형적인 구조를 가질 수 있다. 




# 🚀 Code

> [StyleGAN from scartch (pytorch)](https://github.com/inhopp/StyleGAN)

| Sample 1 | Sample 2 |
|:-:| :-: |
|  |  |



<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}