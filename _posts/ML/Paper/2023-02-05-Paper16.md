---
title:  "[Paper Review] Conditional Image Synthesis with Auxiliary Classifier GANs (ACGANs)" 

categories:
  -  Paper
tags:
  - [ML, Generative]

toc: true
toc_sticky: true

date: 2023-02-05
last_modified_at: 2023-02-05
---

**Main Reference: <br>- [ACGANs Paper](https://arxiv.org/abs/1610.09585)**
{: .notice--primary}

<br>


# 🚀 Introduction

최근 GANs은 생성분야에서 괜찮은 성능을 보이며 큰 주목을 받아왔다. 하지만 high resolution 이미지를 만족스럽게 생성해내지 못했고 특히 생성해야 할 class의 종류가 많아지면 문제가 더 심각해졌다. 본 논문에서는 Discriminator에 보조 디코더(Auxiliary Classifier)를 추가하는 방식으로 문제에 접근했다. 이외에도 high resolution으로 생성하는 것이 왜 중요한지, 생성된 이미지들을 어떻게 평가할 것인지 등의 내용들을 다룬다.


<br>

# 🚀 AC-GANs (Auxiliary Classifier GANs)

![acgan1](https://user-images.githubusercontent.com/96368476/216902221-293e4514-2efd-440a-8c65-fb14f88eef5c.png){: width="60%" height="70%" .align-center}

$$ \textbf{L}_{S} =  \mathbb{E}\left [ logP(\text{S = real} | X_{real}) \right ] + \mathbb{E}\left [ logP(\text{S = fake} | X_{fake}) \right ] $$

$$ \textbf{L}_{C} =  \mathbb{E}\left [ logP(\text{C = c} | X_{real}) \right ] + \mathbb{E}\left [ logP(\text{C = c} | X_{fake}) \right ] $$

Auxiliary Classifier GAN은 Conditional GAN과 유사한 구조를 가지고 있다. C-GAN과의 차이는 discriminator가 sample의 class도 판단하는 것이다. 즉 D는 $\textbf{L}_{C} + \textbf{L}_{S}$ 를 maximize 하도록, G는 $\textbf{L}_{C} - \textbf{L}_{S}$ 를 maximize 하도록 학습한다. 이러한 Loss fuction을 가진 모델은 단순히 주어진 이미지가 real이냐 fake냐를 구분하는 것이 아니라, 특정 class에 대해 주어진 이미지가 real인지 fake인지를 구분한다. 비슷한 이야기처럼 들리지만 결과적으로 기존 모델에 비해 학습이 안정적이며 성능이 좋아진다. 무엇보다 특정 class에 대한 학습이 진행되기 때문에 large dataset을 쪼개서 학습할 수 있다. 예를 들어 1000개의 class를 가진 imagenet을 학습하고 싶다면 각 10개의 class를 담당하는 AC-GANs 모델 100개를 앙상블해 사용할 수 있다는 것이다. 이러한 장점은 class의 갯수가 증가하면 모델의 성능이 크게 감소하는 GAN기반 모델에서 큰 의미를 가진다.


<br>

# 🚀 Results

![acgan4](https://user-images.githubusercontent.com/96368476/216963112-6d62ac5c-c0eb-414e-aa25-84715c2a4b36.png){: width="60%" height="70%" .align-center}

내 생각에 AC-GAN의 가장 큰 장점은 large dataset을 쪼개서 학습할 수 있다는 것이다. 현실적으로 학습비용(특히 속도)이 아주 중요하기 때문이다. 근데 이러한 이점을 빼고도 그냥 성능이 좋다고 한다. 그림의 왼쪽은 기존 생성모델을 이용해 imagenet 이미지를 생성, 오른쪽 그림은 AC-GAN으로 생성한 이미지이다.

<br>

## Generating high resolution images improves discriminability

| Inception accuracy | accuracy by resolution |
|:-:|:-:|
| ![acgan2](https://user-images.githubusercontent.com/96368476/216911528-c0ee9f6e-f331-4dd8-aebc-123133797b93.png) | ![acgan3](https://user-images.githubusercontent.com/96368476/216911539-c752c284-5ad1-4391-97e1-e6d282c94452.png) |

만약 128x128 크기의 이미지를 생성한다고 해보자. 처음부터 128x128로 directly generate하는 방법과 258x258로 생성한 뒤 resize로 줄이는 방법에 성능차이가 있을까? 저자들은 후자의 방식이 더 뛰어남을 보여주며 high resolution 이미지 생성의 중요성을 말한다. 먼저 생성된 이미지를 평가하는 기준을 inception accuracy로 제시하였다. Inception accuracy란 생성된 이미지를 classification 모델인 inception에 집어 넣었을 때 output으로 나온 정확도이다. 왼쪽 그림처럼 inception 모델이 명확하게 구분할수록(discriminability가 높을수록) 생성된 이미지의 품질이 좋다는 뜻이다. 오른쪽 그림의 빨간 선은 128x128로 생성한 이미지를 resize하며 구한 inception accuracy, 파란 선은 64x64로 생성하여 resize한 결과이다. 이와 같은 결과는 이미지뿐 아니라 오디오 등 다른 생성분야에서도 동일할 것으로 예상된다.


<br>


## Measuring the Diversity of Generated Images

앞서 사용한 inception accuracy는 생성된 이미지 각각의 품질을 평가할 수 있지만 이미지들의 분포를 평가하지 못한다. 즉 특정 class에 대해 모델이 mode collapsed 되어 비슷한 이미지들만 생성하는지, train dataset만큼 다양한 이미지들을 생성하는지 알지 못한다. 본 논문에서는 MS-SSIM을 이용하여 생성된 이미지들의 다양성을 정량적으로 분석한다. MS-SSIM(Multi-scale structural smilarity)는 두 이미지가 얼마나 비슷한지를 human perceptual하게 평가한 지표이다. 

![acgan4](https://user-images.githubusercontent.com/96368476/216916975-2d0e66f2-759b-4990-ac25-05c199ff7253.png){: width="60%" height="70%" .align-center}

저자들은 각 class에 대해 생성된 이미지들 중 랜덤하게 100쌍을 뽑아 MS-SSIM 평균 값을 구했다. 이렇게 구한 mean MS-SSIM score 점수가 높다면 생성된 이미지들이 서로 비슷하다는 의미이고, 따라서 sample들의 diversity가 작다는 의미이다. 반대로 MS-SSIM score가 낮다면 sample들의 다양성이 높다는 의미이다.


| MS-SSIM during training | generated data vs source data |
|:-:|:-:|
| ![acgan6](https://user-images.githubusercontent.com/96368476/216917038-300d73a0-781c-4260-b4c6-f9d3606fdeb3.png) | ![acgan5](https://user-images.githubusercontent.com/96368476/216917031-dfd8b098-b7ee-4fb9-bc51-6920c26937de.png) |

- Training 동안 mean MS-SSIM score 추적
  - black line : 성공적인 class에 대해서는 학습할수록 MS-SSIM 감소 (다양해짐)
  - red line : Collapsed class는 학습이 진행될수록 MS-SSIM 증가
- Generated data vs Source data (mean MS-SSIM score 비교)
  - source data의 경우 가장 높은 mean MS-SSIM score는 0.25
  - generated data도 전체 class의 85%가 0.25 이하의 mean MS-SSIM score를 가짐
  - 즉 generated data도 source data 못지않은 다양성을 지닌다.

다만 sample의 다양성을 평가할 때 MS-SSIM metric이 최선인가에 대한 의문은 남아있다. MS-SSIM은 pixel space 위에서의 엔트로피를 계산하는 것이 아니라 사람이 이미지를 어떻게 인식하는지 human perceptual에 대한 지표이기 때문이다.


<br>


## Searching for signatures of overfitting

생성모델을 다룰 때 항상 체크해봐야 할 문제점은 generator가 source data를 copy하는 방식으로 overfitting 되었는가 하는 것이다. 이는 DC-GANs에 나온 방법처럼 latent space를 걸어보면(waking) 알 수 있다. 만약 generator가 overfitting 되어 있다면 latent space 위에서의 작은 움직임이 생성되는 이미지에서 큰 변화를 일으킬 것이다.

![acgan8](https://user-images.githubusercontent.com/96368476/216952315-3e6a01f9-e48a-4317-845e-f1721c7ec36b.png){: width="60%" height="70%" .align-center}

- Top : latent space 위에서 부드럽게 움직이면 생성되는 이미지도 부드럽게 변화한다.
- Bottom : noise 부분은 그대로 둔 체 concat하는 class 정보만 변경하니 이미지의 texture만 변하는 것을 볼 수 있다.


<br>


## Measuring the effect of class splits on image sample quality

![acgan9](https://user-images.githubusercontent.com/96368476/216952374-eaabf4d9-2b2e-468c-8532-148fafb63250.png){: width="60%" height="70%" .align-center}

앞서 언급했듯이 AC-GAN의 generator는 특정 class에 대한 이미지 생성을 학습하므로 large dataset을 쪼개서 학습할 수 있다(쪼개서 학습하고 앙상블하면 그만). 이는 Training cost 관점에서 굉장히 큰 이득이다. 뿐만 아니라 쪼개서 학습할 시 생성되는 image의 quality도 좋아진다는 것이 본 파트의 내용이다. 위 표와 같이 10개의 class들로 쪼개서 학습해야 비로소 source data와 비슷한 mean MS-SSIM score를 달성할 수 있다. 하지만 마냥 쪼갠다고 좋아지는 것은 아니라고 한다. Num of classes를 1로 줄였더니 모델의 성능이 크게 떨어졌다고 한다. 주어진 Dataset에 대한 최적의 분할은 좀 더 연구되어야 한다고 한다.


<br>



# 🚀 Code

> 추가 예정


<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}