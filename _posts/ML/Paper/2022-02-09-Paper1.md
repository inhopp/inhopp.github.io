---
title:  "[논문 리뷰] Image Style Transfer Using Convolutional Neural Networks" 

categories:
  -  Paper
tags:
  - [ML, Paper]

toc: true
toc_sticky: true

date: 2022-02-09
last_modified_at: 2022-02-09
---

**Main Reference: <br>- [Deep Learning for Computer Vision](https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r) <br>- [꼼꼼한 딥러닝 논문 리뷰와 코드 실습](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice)** 
{: .notice--warning}


**[Image Style Transfer Using Convolutional Neural Networks](https://github.com/inhopp/inhopp/files/8025046/Image.Style.Transfer.paper.pdf)**
{: .notice--primary}



<br>

# 🚀 Introduction

![3](https://user-images.githubusercontent.com/96368476/153019796-222dba35-08f7-4d7d-8fea-2d1d1dafa7b6.jpg)

Image Style Transfer란 Content 이미지 형상 위에 style 이미지의 style을 입히는 것이다. 그림과 같이 풍경 사진 위에 유명 화가들의 화풍을 적용하는 것이다. 논문에 나온 방식은 noise image에서 시작해 content와 style을 reconstruction 한다. 즉, cnn의 가중치들은 고정시키고 noise 이미지를 업데이트 한다. 논문에서 사용한 cnn 모델은 pre-trained VGG19 이다.

<br>

![4](https://user-images.githubusercontent.com/96368476/153026588-622ca670-cb34-4f18-832e-e6dd5588da3f.jpg)
{: width="60%" height="70%"}

논문의 핵심 내용은 다음과 같다.
- 이미지의 style을 어떻게 정의할 것인가?
- content와 style을 어떻게 reconstruction 할 것인가?




<br>


# 🚀 Content Reconstruction

content 이미지를 reconstruction하기 위해 content loss 함수를 정의한다. 이 함수는 L번째 convolution layer에 존재하는 i번째 필터에 대응하는 F matrix로 표현된다.

![paper1-17](https://user-images.githubusercontent.com/96368476/153029638-cebd1487-704f-412d-bf0d-a992ec5b7b38.jpg)
{: width="60%" height="70%"}
![6](https://user-images.githubusercontent.com/96368476/153029592-98300888-3823-4afd-9444-8f1bb124057c.jpg)
{: width="60%" height="70%"}

- F: noise image x를 넣었을 때
- P: content image p를 넣었을 때 (상수)

<br>

여기서 특이한 점은 모든 필터를 사용해 업데이트하지 않고 4번째 layer 1번 째 필터만을 이용해 reconstruction 한다. 실제 코드를 돌려보면 업데이트 속도가 굉장히 느려서 필터의 개수를 제한하는 것은 이해가 간다. 그런데 왜 하필 conv4_1 필터를 사용하는 것일까?

<br>

![7](https://user-images.githubusercontent.com/96368476/153031734-4147c747-7327-4c8c-bbe0-5ba147d2d7f2.jpg)

Content Reconstructions부분을 살펴보자. a는 첫번 째 레이어에 존재하는 필터를 이용해 reconstruction 한 그림이고 그 중 특정 부분을 확대한 그림이 아래의 것이다. 오른쪽으로 갈수록 즉, 깊은 layer의 필터를 사용한 것일수록 해상도는 떨어진다. 이는 깊은 layer의 필터일수록 더 넓은 영역을 커버하고, 고차원의 특징을 표현하기 때문이다. 

<br>

![8](https://user-images.githubusercontent.com/96368476/153033127-d0c8ecb9-9b7c-4f4b-a934-1312b145aaca.jpg)
{: width="60%" height="70%"}

위 그림은 Content Image를 각각 Conv2_2 필터, Conv4_2 필터를 이용해 reconstruction한 것이다. Conv2_2 필터를 이용한 경우, 확대한 사진을 보면 content image의 저차원 특징이 너무 선명해서 단순히 색깔만 입혀놓은 듯 하다. 반면 Conv4_2 필터를 이용하니 해상도가 떨어지지만, 오히려 더 자연스럽게 스타일이 표현된 듯하다.





<br>


# 🚀 Style Reconstruction

본 논문에서는 'Style'을 Gram matrix G라는 행렬을 이용해 정의한다. Gram matrix가 무엇인지 살펴보자.

- 필터의 개수: N+1 (0,1,...,N)
- M: feature map의 가로*세로

![paper1-18](https://user-images.githubusercontent.com/96368476/153035219-aef94db0-bc40-43ed-9624-570963077e4c.jpg)
![paper1-19](https://user-images.githubusercontent.com/96368476/153035224-e5afb876-8731-44e7-91aa-966adfb4dd1a.jpg)
![paper1-20](https://user-images.githubusercontent.com/96368476/153035225-0cfefc24-0e69-4322-9927-d51703fefdd0.jpg)
![paper1-21](https://user-images.githubusercontent.com/96368476/153035227-c51387b1-7eec-4e53-88c2-4bff56ba0298.jpg)
![paper1-22](https://user-images.githubusercontent.com/96368476/153035232-07ceb49e-81b1-4222-b446-314fe6e21a2c.jpg)

- 논문에서 제시한 스타일이란?
- **<span style="color:red">Correlations between the different filter responses</span>**


![9](https://user-images.githubusercontent.com/96368476/153037303-e85c8fdc-c359-454c-8fb6-803bfb7ff48f.jpg)
{: width="50%" height="60%"}

- Gram matrix는 크기가 크기 때문에 4MN으로 나누는 정규화 텀을 거치는 듯 하다.
- A는 style image의 Gram matrix (상수)
- content reconstruction과 마찬가지로 모든 layer를 사용하지 않고 conv1, conv2, conv3, conv4, conv5 다섯 개의 layer만 사용한다.
  - 성능 이슈 때문인 듯
- 이때 w는 1/5로 지정해준 하이퍼 파라미터 이다.

<br>

![11](https://user-images.githubusercontent.com/96368476/153039545-e9b3cc96-10bb-481d-9488-c825f9e1be28.jpg)
{: width="50%" height="60%"}

- Gradient를 computed analytically하면서 툭 던져주는데 아직 이해하지 못했다. 좀 더 고민해봐야겠다.


<br>


# 🚀 Style Transfer

![10](https://user-images.githubusercontent.com/96368476/153039052-cf473197-b723-46e9-9f2f-b16d5770d70c.jpg)

이제 content loss와 style loss를 정의했으니 total loss를 정의할 수 있다. 이때 style loss의 정규화 텀 때문인지 알파가 1, 베타가 1000 이런 식이더라. 또 하나 특이한 점은 LBFGS 라는 처음 보는 optimizer를 쓰던데 tensorflow core에서는 adma써도 괜찮다고 한다. 아마 옛날에 쓰던 optimizer인가 보다.


<br>


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}