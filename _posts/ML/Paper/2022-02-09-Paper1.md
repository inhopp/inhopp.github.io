---
title:  "[논문 리뷰] Image Style Transfer Using Convolutional Neural Networks" 

categories:
  -  Paper
tags:
  - [ML, Paper]

toc: true
toc_sticky: true

date: 2022-02-09
last_modified_at: 2022-02-09
---

**Main Reference: <br>- [Deep Learning for Computer Vision](https://www.youtube.com/watch?v=dJYGatp4SvA&list=PL5-TkQAfAZFbzxjBHtzdVCWE0Zbhomg7r) <br>- [꼼꼼한 딥러닝 논문 리뷰와 코드 실습](https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice)** 
{: .notice--warning}


**[Image Style Transfer Using Convolutional Neural Networks](https://github.com/inhopp/inhopp/files/8025046/Image.Style.Transfer.paper.pdf)**
{: .notice--primary}



<br>

# 🚀 Introduction

![3](https://user-images.githubusercontent.com/96368476/153019796-222dba35-08f7-4d7d-8fea-2d1d1dafa7b6.jpg)
{: width="60%" height="70%"}

Image Style Transfer란 Content 이미지 형상 위에 style 이미지의 style을 입히는 것이다. 그림과 같이 풍경 사진 위에 유명 화가들의 화풍을 적용하는 것이다. 논문에 나온 방식은 noise image에서 시작해 content와 style을 reconstruction 한다. 즉, cnn의 가중치들은 고정시키고 noise 이미지를 업데이트 한다. 논문에서 사용한 cnn 모델은 pre-trained VGG19 이다.

<br>

![4](https://user-images.githubusercontent.com/96368476/153026588-622ca670-cb34-4f18-832e-e6dd5588da3f.jpg)
{: width="50%" height="60%"}

논문의 핵심 내용은 다음과 같다.
- 이미지의 style을 어떻게 정의할 것인가?
- content와 style을 어떻게 reconstruction 할 것인가?




<br>


# 🚀 Content Reconstruction

content 이미지를 reconstruction하기 위해 content loss 함수를 정의한다. 이 함수는 L번째 convolution layer에 존재하는 i번째 필터에 대응하는 F matrix로 표현된다.

![paper1-17](https://user-images.githubusercontent.com/96368476/153029638-cebd1487-704f-412d-bf0d-a992ec5b7b38.jpg)
{: width="50%" height="60%"}

\[L_{content}(\vec{p},\vec{x},l) = \frac{1}{2}\sum_{i,j}^{}(F_{ij}^{l}-P_{ij}^{l})^{2}\]

\[\frac{\partial L_{content}}{\partial F_{ij}^{l}} = (F^{l}-P^{l})_{ij}\]

- p: content image
- x: input image (noise)
- l: l번째 layer
- F: noise image x를 넣었을 때 활성화 값
- P: content image p를 넣었을 때 활성화  값 (상수)

<br>

여기서 특이한 점은 모든 필터를 사용해 업데이트하지 않고 4번째 layer 1번 째 필터만을 이용해 reconstruction 한다. 실제 코드를 돌려보면 업데이트 속도가 굉장히 느려서 필터의 개수를 제한하는 것은 이해가 간다. 그런데 왜 하필 conv4_1 필터를 사용하는 것일까?

<br>

![7](https://user-images.githubusercontent.com/96368476/153031734-4147c747-7327-4c8c-bbe0-5ba147d2d7f2.jpg)

Content Reconstructions부분을 살펴보자. a는 첫번 째 레이어에 존재하는 필터를 이용해 reconstruction 한 그림이고 그 중 특정 부분을 확대한 그림이 아래의 것이다. 오른쪽으로 갈수록 즉, 깊은 layer의 필터를 사용한 것일수록 해상도는 떨어진다. 이는 깊은 layer의 필터일수록 더 넓은 영역을 커버하고, 고차원의 특징을 표현하기 때문이다. 

<br>

![8](https://user-images.githubusercontent.com/96368476/153033127-d0c8ecb9-9b7c-4f4b-a934-1312b145aaca.jpg)
{: width="50%" height="60%"}

위 그림은 Content Image를 각각 Conv2_2 필터, Conv4_2 필터를 이용해 reconstruction한 것이다. Conv2_2 필터를 이용한 경우, 확대한 사진을 보면 content image의 저차원 특징이 너무 선명해서 단순히 색깔만 입혀놓은 듯 하다. 반면 Conv4_2 필터를 이용하니 해상도가 떨어지지만, 오히려 더 자연스럽게 스타일이 표현된 듯하다.





<br>


# 🚀 Style Reconstruction

본 논문에서는 'Style'을 Gram matrix G라는 행렬을 이용해 정의한다. Gram matrix가 무엇인지 살펴보자.

- 필터의 개수: N+1 (0,1,...,N)
- M: feature map의 가로*세로

![17](https://user-images.githubusercontent.com/96368476/153115154-f2fad544-7f4b-4561-a552-bf5aaeeb9595.jpg)
{: width="50%" height="60%"}
![15](https://user-images.githubusercontent.com/96368476/153115141-c0d3d04b-d9b9-48ae-aae1-1461080df2d8.jpg)
{: width="50%" height="60%"}
![18](https://user-images.githubusercontent.com/96368476/153115582-57b8f028-3944-413a-b793-fd267e76bcfa.jpg)
{: width="50%" height="60%"}

- 논문에서 제시한 스타일이란?
- **<span style="color:red">Correlations between the different filter responses</span>**

<br>


\[G_{ij}^{l} = \sum_{k}^{}F_{ik}^{l}F_{jk}^{l}\]

\[E_{l} = \frac{1}{4N_{l}^{2}M_{l}^{2}}\sum_{i,j}^{}(G_{ij}^{l}-A_{ij}^{l})^{2}\]

\[L_{style}(\vec{a}, \vec{x}) = \sum_{l=0}^{L}w_{l}E_{l}\]

\[\frac{\partial E_{l}}{\partial F_{ij}^{l}} = \frac{1}{N_{l}^{2}M_{l}^{2}} {({(F^{l})}^{T}(G^{l} - A^{l}))}_{ji}\]

- Gram matrix는 크기가 크기 때문에 4MN으로 나누는 정규화 텀을 거치는 듯 하다.
- A는 style image의 Gram matrix (상수)
- content reconstruction과 마찬가지로 모든 layer를 사용하지 않고 conv1, conv2, conv3, conv4, conv5 다섯 개의 layer만 사용한다.
  - 성능 이슈 때문인 듯
- 이때 w는 1/5로 지정해준 하이퍼 파라미터 이다.
  - l = 0, 1, 2, 3, 4 (논문에서는 5개의 layer 사용)
- Gradient를 computed analytically하면서 툭 던져주는데 아직 이해하지 못했다. 좀 더 고민해봐야겠다.


<br>


# 🚀 Style Transfer

![10](https://user-images.githubusercontent.com/96368476/153039052-cf473197-b723-46e9-9f2f-b16d5770d70c.jpg)

이제 content loss와 style loss를 정의했으니 total loss를 정의할 수 있다. 이때 style loss의 정규화 텀 때문인지 알파가 1, 베타가 1000 이런 식이더라. 또 하나 특이한 점은 LBFGS 라는 처음 보는 optimizer를 쓰던데 tensorflow core에서는 adma써도 괜찮다고 한다. 아마 옛날에 쓰던 optimizer인가 보다.





<br>



# 🚀 Result

## Trad-off between contentand style matching

![13](https://user-images.githubusercontent.com/96368476/153042093-f0ba076b-a340-4f87-8246-a8e81d1b0977.jpg)
{: width="60%" height="70%"}

\[L_{total} = \alpha L_{content} + \beta L_{style}\]

- 알파/베타 비율을 조정하면서 content에 중점을 둘지 style에 중점을 둘지 선택할 수 있다. 다만 서로 trade-off 관계이다.


<br>



## Initialization of gradient descent

![12](https://user-images.githubusercontent.com/96368476/153042085-ec98d672-c94e-4ad9-b0fa-85ed1f2e81a4.jpg)
{: width="60%" height="70%"}

- 원래 noise image를 input으로 두고 업데이트 하는 방식이었는데, content image 또는 style image를 초기값으로 둬도 괜찮다고 한다.
- A가 content image를 input으로 둔 결과
- B가 style image를 input으로 둔 결과이다.



<br>



## Photorealistic style transfer

![14](https://user-images.githubusercontent.com/96368476/153044603-20cbc839-a7de-4679-b71c-a7670b88ef67.jpg)
{: width="60%" height="70%"}

- Artistic style이 아닌 arbitrary image로도 style transfer가 가능할까?
- 예외적인 경우가 아니면 힘들다고 함
- 해상도가 높으면 성능이 못 따라감
- noise가 많이 낌
  - 경계가 애매한 art style에서는 괜찮았음
  - photorealistic style에서는 문제가 됨




<br>



# 🚀 Discussion

저자들이 제시한 스타일(feature map들의 상관관계)의 정의는 완벽하지 않다. 고흐의 '별이 빛나는 밤' style을 예로 들어보자. 사람이 보기에 그림의 '별'은 스타일이 아닌 object이다. 하지만 style transfer에서는 별을 스타일로 인식한다. 아직 발전해야할 일이 남아있다. 인간이 짱이다.






<br>



# 🚀 실습

**[Tutoral Code](https://github.com/inhopp/ML_code/blob/main/Style_Transfer_tutorial.ipynb)**
{: .notice--primary}

일본 여행에 좋은 기억이 많아서, 일본 풍경으로 tutoral 코드를 돌려봤다. tensorflow, pytorch 두 버전으로 해봤는데 pytorch가 더 직관적으로 보기 편했다. 그리고 gpu 많이 쓰니까 코랩에서 못쓰게 막더라.

![paper1-23](https://user-images.githubusercontent.com/96368476/153046444-7823543b-bca8-4ec9-8bb6-3a589b671fa8.jpg)
![paper1-24](https://user-images.githubusercontent.com/96368476/153046457-0911275b-3a3b-4c76-b58c-46c88717f27b.jpg)





<br>


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}