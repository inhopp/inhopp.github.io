---
title:  "[논문 리뷰] Fast R-CNN" 

categories:
  -  Paper
tags:
  - [ML, Object Detection]

toc: true
toc_sticky: true

date: 2022-09-13
last_modified_at: 2022-09-13
---

**Paper: <br>- [Fast R-CNN](https://github.com/inhopp/inhopp/files/9548881/Fast.RCNN.pdf)**
{: .notice--primary}


<br>

# 🚀 Abstract

Fast R-CNN은 기존의 Detection 모델인 R-CNN과 SPPnet을 개선해 정확도와 속도 모두를 높이는데 성공했다. 특히 test inference의 경우 R-CNN에 비해 무려 213배나 빠르다.



<br>

# 🚀  Introduction

최근 (2015년) cnn을 통한 분류 작업은 큰 성과를 이루었다. 다만 detection의 경우 classification에 비해 문제가 조금 복잡해진다. 물체의 정확한 위치를 파악해야 하기 때문인데, 이게 생각보다 어려운 작업이다.
- 수많은 영역(RoI)들을 확인해봐야 한다. (R-CNN 기준 이미지당 2000개의 영역)
- Selective Search를 통해 제안된 영역은 대락적인 위치이므로 조정 작업이 필요하다.


## R-CNN and SPPnet

| R-CNN | SPPnet |
|:-:|:-:|
| ![rcnn](https://user-images.githubusercontent.com/96368476/189808714-226b6b1b-80e5-4bf0-b5e8-480df65f0f1b.png) | ![sppnet](https://user-images.githubusercontent.com/96368476/189808721-c31e4062-b48e-4d40-a760-0f428c6315cb.png) | 

R-CNN의 경우 성공적인 detection 모델이라 할 수 있지만 다음과 같은 단점들이 존재한다.

1. Training is multi-stage pipeline
  - classification 따로, box regression 따로 계산함
  - 심지어 classification은 cnn 거친 후 SVM 계산

2. Training is expensive in space and time
  - 수많은 영역에 대해 inference를 해봐야 하니 시간도 오래걸리고, 메모리도 엄청 많이 필요함

3. Detection is slow
  - R-CNN의 경우 이미지 한 장 inference하는데 47초나 필요함.
  - real-time은 어림도 없는 시간

R-CNN 이후 제안된 SPPnet의 경우 전체 이미지에 먼저 convolution연산 후 작업들을 수행한다.
따라서 낭비되던 많은 연산들을 공유하고, 속도도 개선시켰다. 하지만 여전히 multi-pipeline이라는 단점은 해결하지 못했고, SPPnet에서 제안한 fine-tuning 기법으로는 conv layer를 학습하지 못했다(R-CNN은 가능했다). <br>

본 논문에서는 위 단점들을 극복하고 다음과 같은 특징을 가진 새로운 Detection 모델, Fast R-CNN을 제안한다.
- accuracy & speed 모두 개선
- multi-stage가 아닌 single-stage training
- 네트워크의 모든 layer들을 학습할 수 있음



<br>


# 🚀 Fast R-CNN architecture and training

![architecutre](https://user-images.githubusercontent.com/96368476/189818457-e55f8520-f65e-43c9-84d4-b11e20ecd0a4.png){: width="70%" height="80%" .align-center}

Fast R-CNN의 핵심은 다음 두 가지라 할 수 있다. <br>
1. 기존의 방식은 RoI를 input으로 받지만, fast rcnn은 전체 이미지(원본)를 input으로 받는다.
2. classify와 box regression을 single-stage로 학습한다.

이러한 차이점은 단순해 보이지만 학습 방법에 큰 변화를 가져온다.

<br>

## RoI pooling layer

![pooling](https://user-images.githubusercontent.com/96368476/189819731-b4a330f6-1f83-4a92-82ce-7917be9869a9.png){: width="50%" height="60%" .align-center}

원본 이미지에서 region proposal → roi projection → fixed size로 max pooling (7x7)


<br>


## Initializing from pretrained networks

Fast R-CNN은 기존의 R-CNN과 같이 pretrined network(e.g., VGG16)를 사용하는데, 다음과 같은 변환을 해주면 된다.

- 네트워크의 마지막 pooling layer를 RoI pooling layer로 변환
- 마지막 softmax layer를 (classify + box regression) softmax layer로 변환
- 네트워크가 두 개의 input, 이미지 + RoI 를 받도록 변경


<br>


## Fine-tuning for detection

### Multi-task loss

$$ \textbf{L}(p,u,t^{u},v) = \textbf{L}_{cls}(p,u) + \lambda [u \geq 1]\textbf{L}_{loc}(t^{u},v) $$

$$ p = (p_{0}, p_{1}, \cdots  , p_{k}) $$ 

$$ t^{u} = (t_{x}^{u}, t_{y}^{u}, t_{w}^{u}, t_{h}^{u}) $$

$$ \textbf{L}_{cls}(p, u) = -log(p_{u}) $$

$$ \textbf{L}_{loc}(t^{u}, v) = \sum_{i\in {x,y,w,h}}^{} smmoth_{L_{1}}(t_{i}^{u}-v_{i}) $$

$$ smooth_{L_{1}}(x) = 
\begin{cases}
0.5x^{2} & \text{ if } |x|<1 \\
|x| - 0.5 & \text{ otherwise, } 
\end{cases} $$

- p : (k+1)개 클래스에 대한 class score ( k + background=0)
- u : inference하는 객체의 실제 class
- t^u : class u에 대한 bounding box 비율을 조정하는 값
- v : 실제 bounding box 좌표
- λ : classify & box regression 비율 조정 (default = 1)
- [ u≥1 ] : u=0일 경우 0 (background인 경우 box regression 수행x), 나머지 1
- R-CNN, SPP에서 box regression을 구할 때에는 L2 loss 사용했는데 종종 gradient exploding 발생. → L1으로 변경


<br>


### Mini-batch sampling








<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}