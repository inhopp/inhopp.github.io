---
title:  "[Paper Review] Fast R-CNN" 

categories:
  -  Paper
tags:
  - [ML, Object Detection]

toc: true
toc_sticky: true

date: 2022-09-13
last_modified_at: 2022-09-13
---

**Paper: <br>- [Fast R-CNN](https://github.com/inhopp/inhopp/files/9548881/Fast.RCNN.pdf)**
{: .notice--primary}


<br>

# ğŸš€ Abstract

Fast R-CNNì€ ê¸°ì¡´ì˜ Detection ëª¨ë¸ì¸ R-CNNê³¼ SPPnetì„ ê°œì„ í•´ ì •í™•ë„ì™€ ì†ë„ ëª¨ë‘ë¥¼ ë†’ì´ëŠ”ë° ì„±ê³µí–ˆë‹¤. íŠ¹íˆ test inferenceì˜ ê²½ìš° R-CNNì— ë¹„í•´ ë¬´ë ¤ 213ë°°ë‚˜ ë¹ ë¥´ë‹¤.



<br>

# ğŸš€  Introduction

ìµœê·¼ (2015ë…„) cnnì„ í†µí•œ ë¶„ë¥˜ ì‘ì—…ì€ í° ì„±ê³¼ë¥¼ ì´ë£¨ì—ˆë‹¤. ë‹¤ë§Œ detectionì˜ ê²½ìš° classificationì— ë¹„í•´ ë¬¸ì œê°€ ì¡°ê¸ˆ ë³µì¡í•´ì§„ë‹¤. ë¬¼ì²´ì˜ ì •í™•í•œ ìœ„ì¹˜ë¥¼ íŒŒì•…í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì¸ë°, ì´ê²Œ ìƒê°ë³´ë‹¤ ì–´ë ¤ìš´ ì‘ì—…ì´ë‹¤.
- ìˆ˜ë§ì€ ì˜ì—­(RoI)ë“¤ì„ í™•ì¸í•´ë´ì•¼ í•œë‹¤. (R-CNN ê¸°ì¤€ ì´ë¯¸ì§€ë‹¹ 2000ê°œì˜ ì˜ì—­)
- Selective Searchë¥¼ í†µí•´ ì œì•ˆëœ ì˜ì—­ì€ ëŒ€ë½ì ì¸ ìœ„ì¹˜ì´ë¯€ë¡œ ì¡°ì • ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.


## R-CNN and SPPnet

| R-CNN | SPPnet |
|:-:|:-:|
| ![rcnn](https://user-images.githubusercontent.com/96368476/189808714-226b6b1b-80e5-4bf0-b5e8-480df65f0f1b.png) | ![sppnet](https://user-images.githubusercontent.com/96368476/189808721-c31e4062-b48e-4d40-a760-0f428c6315cb.png) | 

R-CNNì˜ ê²½ìš° ì„±ê³µì ì¸ detection ëª¨ë¸ì´ë¼ í•  ìˆ˜ ìˆì§€ë§Œ ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ì ë“¤ì´ ì¡´ì¬í•œë‹¤.

1. Training is multi-stage pipeline
  - classification ë”°ë¡œ, box regression ë”°ë¡œ ê³„ì‚°í•¨
  - ì‹¬ì§€ì–´ classificationì€ cnn ê±°ì¹œ í›„ SVM ê³„ì‚°

2. Training is expensive in space and time
  - mini-batch samplingì„ ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ì˜ RoIë“¤ë¡œ ì§„í–‰
  - ì„œë¡œ ë‹¤ë¥¸ ì´ë¯¸ì§€ ì˜ì—­ì— ëŒ€í•´ inferenceë¥¼ í•´ë´ì•¼ í•˜ë‹ˆ ì‹œê°„ë„ ì˜¤ë˜ê±¸ë¦¬ê³ , ë©”ëª¨ë¦¬ë„ ì—„ì²­ ë§ì´ í•„ìš”í•¨

3. Detection is slow
  - R-CNNì˜ ê²½ìš° ì´ë¯¸ì§€ í•œ ì¥ inferenceí•˜ëŠ”ë° 47ì´ˆë‚˜ í•„ìš”í•¨.
  - real-timeì€ ì–´ë¦¼ë„ ì—†ëŠ” ì‹œê°„

R-CNN ì´í›„ ì œì•ˆëœ SPPnetì˜ ê²½ìš° ì „ì²´ ì´ë¯¸ì§€ì— ë¨¼ì € convolutionì—°ì‚° í›„ ì‘ì—…ë“¤ì„ ìˆ˜í–‰í•œë‹¤.
ë”°ë¼ì„œ ë‚­ë¹„ë˜ë˜ ë§ì€ ì—°ì‚°ë“¤ì„ ê³µìœ í•˜ê³ , ì†ë„ë„ ê°œì„ ì‹œì¼°ë‹¤. í•˜ì§€ë§Œ ì—¬ì „íˆ multi-pipelineì´ë¼ëŠ” ë‹¨ì ì€ í•´ê²°í•˜ì§€ ëª»í–ˆê³ , SPPnetì—ì„œ ì œì•ˆí•œ fine-tuning ê¸°ë²•ìœ¼ë¡œëŠ” conv layerë¥¼ í•™ìŠµí•˜ì§€ ëª»í–ˆë‹¤(R-CNNì€ ê°€ëŠ¥í–ˆë‹¤). <br>

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” ìœ„ ë‹¨ì ë“¤ì„ ê·¹ë³µí•˜ê³  ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì§•ì„ ê°€ì§„ ìƒˆë¡œìš´ Detection ëª¨ë¸, Fast R-CNNì„ ì œì•ˆí•œë‹¤.
- accuracy & speed ëª¨ë‘ ê°œì„ 
- multi-stageê°€ ì•„ë‹Œ single-stage training
- ë„¤íŠ¸ì›Œí¬ì˜ ëª¨ë“  layerë“¤ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ



<br>


# ğŸš€ Fast R-CNN architecture and training

![architecutre](https://user-images.githubusercontent.com/96368476/189818457-e55f8520-f65e-43c9-84d4-b11e20ecd0a4.png){: width="70%" height="80%" .align-center}

Fast R-CNNì˜ í•µì‹¬ì€ ë‹¤ìŒ ë‘ ê°€ì§€ë¼ í•  ìˆ˜ ìˆë‹¤. <br>
1. ê¸°ì¡´ì˜ ë°©ì‹ì€ RoIë¥¼ inputìœ¼ë¡œ ë°›ì§€ë§Œ, fast rcnnì€ ì „ì²´ ì´ë¯¸ì§€(ì›ë³¸)ë¥¼ inputìœ¼ë¡œ ë°›ëŠ”ë‹¤.
2. classifyì™€ box regressionì„ single-stageë¡œ í•™ìŠµí•œë‹¤.

ì´ëŸ¬í•œ ì°¨ì´ì ì€ ë‹¨ìˆœí•´ ë³´ì´ì§€ë§Œ í•™ìŠµ ë°©ë²•ì— í° ë³€í™”ë¥¼ ê°€ì ¸ì˜¨ë‹¤.

<br>

## RoI pooling layer

![pooling](https://user-images.githubusercontent.com/96368476/189819731-b4a330f6-1f83-4a92-82ce-7917be9869a9.png){: width="70%" height="80%" .align-center}

ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ region proposal â†’ roi projection â†’ fixed sizeë¡œ max pooling (7x7)


<br>


## Initializing from pretrained networks

Fast R-CNNì€ ê¸°ì¡´ì˜ R-CNNê³¼ ê°™ì´ pretrined network(e.g., VGG16)ë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ë‹¤ìŒê³¼ ê°™ì€ ë³€í™˜ì„ í•´ì£¼ë©´ ëœë‹¤.

- ë„¤íŠ¸ì›Œí¬ì˜ ë§ˆì§€ë§‰ pooling layerë¥¼ RoI pooling layerë¡œ ë³€í™˜
- ë§ˆì§€ë§‰ softmax layerë¥¼ (classify + box regression) softmax layerë¡œ ë³€í™˜
- ë„¤íŠ¸ì›Œí¬ê°€ ë‘ ê°œì˜ input, ì´ë¯¸ì§€ + RoI ë¥¼ ë°›ë„ë¡ ë³€ê²½


<br>


## Fine-tuning for detection

### Multi-task loss

$$ \textbf{L}(p,u,t^{u},v) = \textbf{L}_{cls}(p,u) + \lambda [u \geq 1]\textbf{L}_{loc}(t^{u},v) $$

$$ p = (p_{0}, p_{1}, \cdots  , p_{k}) $$ 

$$ t^{u} = (t_{x}^{u}, t_{y}^{u}, t_{w}^{u}, t_{h}^{u}) $$

- p : (k+1)ê°œ í´ë˜ìŠ¤ì— ëŒ€í•œ class score ( k + background=0)
- u : inferenceí•˜ëŠ” ê°ì²´ì˜ ì‹¤ì œ class
- t^u : class uì— ëŒ€í•œ bounding box ë¹„ìœ¨ì„ ì¡°ì •í•˜ëŠ” ê°’
- v : ì‹¤ì œ bounding box ì¢Œí‘œ
- Î» : classify & box regression ë¹„ìœ¨ ì¡°ì • (default = 1)
- [ uâ‰¥1 ] : u=0ì¼ ê²½ìš° 0 (backgroundì¸ ê²½ìš° box regression ìˆ˜í–‰x), ë‚˜ë¨¸ì§€ 1

<br>

$$ \textbf{L}_{cls}(p, u) = -log(p_{u}) $$

$$ \textbf{L}_{loc}(t^{u}, v) = \sum_{i\in {x,y,w,h}}^{} smmoth_{L_{1}}(t_{i}^{u}-v_{i}) $$

$$ smooth_{L_{1}}(x) = 
\begin{cases}
0.5x^{2} & \text{ if } |x|<1 \\
|x| - 0.5 & \text{ otherwise, } 
\end{cases} $$


- R-CNN, SPPì—ì„œ box regressionì„ êµ¬í•  ë•Œì—ëŠ” L2 loss ì‚¬ìš©í–ˆëŠ”ë° ì¢…ì¢… gradient exploding ë°œìƒ. â†’ L1ìœ¼ë¡œ ë³€ê²½


<br>


### Mini-batch sampling

| R-CNN & SPPnet| Fast R-CNN |
|:-:|:-:|
| <img width="1131" alt="batch1" src="https://user-images.githubusercontent.com/96368476/189883713-b914bf90-d3b2-4140-9eb9-f3746a5edf1a.png"> | <img width="1125" alt="batch2" src="https://user-images.githubusercontent.com/96368476/189883736-9303fc80-cd6c-453d-8ac3-aecde36ff1ea.png"> | 

Fast R-CNNì€ mini-batch sampling ê¸°ë²•ë„ í¬ê²Œ ê°œì„ í–ˆë‹¤. ê¸°ì¡´ì˜ ë°©ì‹ì€ ì„œë¡œ ë‹¤ë¥¸ 128ì¥ì˜ ì´ë¯¸ì§€ì—ì„œ RoIë¥¼ ìƒ˜í”Œë§í•˜ëŠ” ë°©ë²•ì´ì—ˆì§€ë§Œ, ê°œì„ ëœ ë°©ì‹ì€ 2ì¥ì˜ ì´ë¯¸ì§€ì—ì„œ ê° 64ê°œì”© RoIë“¤ì„ ìƒ˜í”Œë§í–ˆë‹¤. 64ê°œì˜ RoI ì¤‘ 25%ëŠ” IoU>0.5ì¸ ì‹¤ì œ object, ë‚˜ë¨¸ì§€ 75%ëŠ” IoUê°€ [0.1,0.5) ì‚¬ì´ì¸ background. ì´ ë¹„ìœ¨( N=2, R=64 )ì€ ì €ìë“¤ì´ ì‹¤í—˜ì ìœ¼ë¡œ ì •í•œ ë¹„ìœ¨ì¸ë°, ì´ëŸ° ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ë©´ ë©”ëª¨ë¦¬ë¥¼ í›¨ì”¬ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤(feature mapì„ ê³µìœ í•˜ë¯€ë¡œ). ë„ˆë¬´ ë‹¹ì—°í•œ ì´ì•¼ê¸°ë¼ ë“œëŠ” ì˜ë¬¸ì ì€ ì™œ ì§„ì‘ í•˜ì§€ ì•Šì•˜ì„ê¹Œ.. 


<br>


### Back-propagation through RoI pooling layers

ë…¼ë¬¸ì— ë“±ì¥í•˜ëŠ” RoI pooling layerëŠ” ì €ìë“¤ì´ ì²˜ìŒ ì œì•ˆí•œ layerì´ê¸° ë•Œë¬¸ì— back-propagation ë°©ë²•ì— ëŒ€í•´ì„œë„ ì†Œê°œí•´ì¤€ë‹¤.

![roi_pool](https://user-images.githubusercontent.com/96368476/189889732-3bab7d10-e793-41d7-a970-96ba5a6c0d99.jpeg){: width="40%" height="50%" .align-center}

$$ \frac{\partial L}{\partial x_{i}} = \sum_{r}^{}\sum_{j}^{}[i = i^{*}(r,j)]\frac{\partial L}{\partial y_{rj}} $$ 

$$ x_{i} : i_{th} \text{ activation input into the RoI pooling layer} $$

$$ y_{rj} : j_{th} \text{ output from the } r_{th} \text{ RoI} $$

$$ y_{rj} = x_{i*(r,j)} \text{  in which  } i*(r,j) = argmax_{i^{'}\in R(r,j)}x_{i^{'}} $$ 



<br>


## Scale invariance

ì €ìë“¤ì€ sclae invariance detectionì„ ìœ„í•´ ë‘ ê°€ì§€ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤.
1. pre-defined sizeë¡œ ë°”ê¾¸ê³  input ë„£ê¸°
2. image-pyramid ë°©ì‹ ì´ìš©

![image_pyramid](https://user-images.githubusercontent.com/96368476/189894543-374ef03f-c901-44ed-bfd2-71eabf3906f2.png){: width="40%" height="50%" .align-center}

ì—¬ê¸°ì„œ ë§í•˜ëŠ” image_pyramidë€ data augmentaion ëŠë‚Œìœ¼ë¡œ í•˜ë‚˜ì˜ ì´ë¯¸ì§€ë¥¼ ì—¬ëŸ¬ ì‚¬ì´ì¦ˆë¡œ ë³€í™˜í•˜ë©° í›ˆë ¨ì‹œí‚¤ëŠ” ë°©ì‹ì´ë‹¤. ì–¸ëœ» ê´œì°®ì€ ë°©ë²•ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, gpu ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì¡ì•„ë¨¹ëŠ” í˜„ì‹¤ì ì¸ ë¬¸ì œë„ ìˆê³  ë§‰ìƒ í•´ë³´ë‹ˆ ì†Œëª¨í•˜ëŠ” ìì›ì— ë¹„í•´ ì„±ëŠ¥ í–¥ìƒì´ ë„ˆë¬´ ì‘ì•˜ë‹¤ê³  í•œë‹¤.



<br>


# ğŸš€ Fast R-CNN detection

![inference](https://user-images.githubusercontent.com/96368476/189895792-604b9081-af53-4fba-93b2-e830cc2b37a0.png){: width="80%" height="90%" .align-center}

Detectionì—ì„œì˜ inference ê³¼ì •ì€ CNNì˜ inferenceì™€ëŠ” ëŠë‚Œì´ ë‹¤ë¥´ë‹¤. ì´ë¯¸ì§€ë‹¹ ëŒ€ëµ 2000ê°œì˜ RoIë“¤ì´ ì¡´ì¬í•˜ê³ , ê° ì˜ì—­ë“¤ì— ëŒ€í•´ ëª¨ë‘ forward ì—°ì‚°ì´ ìˆ˜í–‰ë˜ì–´ì•¼ í•œë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ forward ìˆ˜í–‰ ê²°ê³¼ ë‚˜ì˜¨ scoreë“¤ì„ ì´ìš©í•´ NMSê¹Œì§€ ì§„í–‰í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ inference speedê°€ êµ‰ì¥íˆ ëŠë¦¬ë‹¤. <br>


![latency](https://user-images.githubusercontent.com/96368476/189897944-22c40d61-8a7e-4f6d-858d-144cc479ecc8.png){: width="60%" height="70%" .align-center}

ì´ë•Œ ì €ìë“¤ì€ inference time ì¤‘ fc layerê°€ ì°¨ì§€í•˜ëŠ” ë¹„ì¤‘ì´ ìƒê°ë³´ë‹¤ í›¨ì”¬ í¬ë‹¤ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤. ë‹¨ìˆœ fc layerëŠ” SVDë¥¼ ì´ìš©í•´ ì‰½ê²Œ ì••ì¶•ì´ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— Truncated SVD ë°©ë²•ì„ ì´ìš©í•´ inference ì†ë„ë¥¼ ê°œì„ í–ˆë‹¤.



<br>



# ğŸš€ Main results

> mAP ë§ì´ ì¢‹ì•„ì¡Œì–´ìš”

![mAP](https://user-images.githubusercontent.com/96368476/189902724-c63d0487-ac8b-4bdf-afe1-2f8e04cd76f8.png){: .align-center}

<br>


> training time, test time ëª¨ë‘ ë¹¨ë¼ì¡Œì–´ìš”

![speed](https://user-images.githubusercontent.com/96368476/189902748-3aedd01d-cf47-4a9c-9488-6b6f01a152d7.png){: width="60%" height="70%" .align-center}


<br>


## Which layers to fine-tune

Fast R-CNNì€ SPPnetê³¼ ë‹¬ë¦¬ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ inputìœ¼ë¡œ ë°›ëŠ”ë‹¤. ë”°ë¼ì„œ backbone networkì¸ VGGì˜ weightë“¤ë„ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤. ê·¸ë ‡ë‹¤ë©´ VGGë¥¼ í¬í•¨í•œ ëª¨ë“  layerë“¤ì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì¢‹ì„ê¹Œ? ì‹¤í—˜ ê²°ê³¼ ê·¸ë ‡ì§€ëŠ” ì•Šë‹¤ê³  í•œë‹¤. 

<img width="817" alt="fine_tune" src="https://user-images.githubusercontent.com/96368476/189903698-c9c762c0-e530-449c-952a-6b4a5121040e.png">{: width="60%" height="70%" .align-center}

Fast R-CNN L ëª¨ë¸ì˜ ê²½ìš° VGGì˜ conv2_1 layerë¶€í„° í•™ìŠµí•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ë‹¤ê³  í•œë‹¤.



<br>



# ğŸš€ Design evaluation

## Does multi-task training help?

ê¸°ì¡´ì˜ Detection ëª¨ë¸ì€ classifyì— ëŒ€í•œ loss, locationì— ëŒ€í•œ lossë¥¼ ë”°ë¡œ ê³„ì‚°í–ˆë‹¤. Fast R-CNNì˜ ê²½ìš° ë‘ taskë¥¼ í•©ì¹œ lossë¥¼ ì •ì˜í–ˆëŠ”ë°, í˜¹ì‹œ multi-task trainingì„ í–ˆë‹¤ê°€ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì§€ëŠ” ì•Šì„ê¹Œ? ì´ë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ ì‹¤í—˜ì„ ì§„í–‰í–ˆë‹¤.

![multi-task](https://user-images.githubusercontent.com/96368476/189905089-d98c6d36-0c58-4ede-9426-6c00055e2145.png){: .align-center}

- 1th column : only classify
- 2th column : classify + box regression (disable bounding- box regression at test time) â†’ ê¸°ì¡´ ëª¨ë¸ê³¼ ë¹„êµí•˜ê¸° ìœ„í•´
- 3th column : classify, bbox reg ë”°ë¡œë”°ë¡œ
- 4th column : Fast R-CNN method

ê²°ê³¼ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ì˜¬ëë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ìƒê°í•´ë³´ë©´ bbox locationê³¼ classify ì„±ëŠ¥ì€ ì„œë¡œ correlated í•˜ê¸° ë•Œë¬¸ì— ë‘ ê°œë¥¼ ë¬¶ëŠ” ê²ƒì´ í•©ë¦¬ì ìœ¼ë¡œ ë³´ì¸ë‹¤. 


<br>

## Scale invariance

![sclae](https://user-images.githubusercontent.com/96368476/189909950-d655c684-a9c1-42d2-8311-3b09d0953ab8.png){: width="70%" height="80%" .align-center}

- single scale í•™ìŠµ vs {480, 576, 688, 864, 1200} ê° í¬ê¸°ì— ëŒ€í•´ image pyramidë¥¼ ì´ìš©í•œ í•™ìŠµ
- mAP ì¡°ê¸ˆ ìƒìŠ¹ & inference time í¬ê²Œ ì¦ê°€
- ì‹¬ì§€ì–´ L ëª¨ë¸ì—ì„œëŠ” ë©”ëª¨ë¦¬ ë¬¸ì œë¡œ ì‹¤í—˜ì¡°ì°¨ ëª»í•¨
- ê²°ë¡  : ê·¸ëƒ¥ single sclaeë¡œ í•™ìŠµí•˜ì.


<br>


## Do SVMs outperform softmax?

ê¸°ì¡´ì˜ R-CNN, SPPnetì€ one-vs-rest ë°©ì‹ì˜ SVMsì„ ì´ìš©í•˜ì—¬ classifyë¥¼ ì§„í–‰í–ˆë‹¤. í•˜ì§€ë§Œ Fast R-CNNì˜ ê²½ìš° muli-task pipelineì„ í•©ì¹˜ê¸° ìœ„í•´ softmaxë¡œ ë¶„ë¥˜ë¥¼ í•œë‹¤. í˜¹ì‹œ ì´ ê³¼ì •ì—ì„œ classify ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì§€ëŠ” ì•Šì„ê¹Œ?

![SVM](https://user-images.githubusercontent.com/96368476/189905101-b7c819a9-f6fd-4021-b2b8-82130046c705.png){: width="60%" height="70%" .align-center}

ê²°ê³¼ëŠ” ì‘ ì•„ë‹ˆì•¼. ì„±ëŠ¥ ì¦ê°€ëŠ” ë¯¸ë¯¸í•˜ì§€ë§Œ, one-shot fine tuneì´ ê°€ëŠ¥í•˜ë‹ˆ í›¨ì”¬ ì´ë“ì´ë‹¤.


<br>


## Are more proposals always better?

![Roi](https://user-images.githubusercontent.com/96368476/189905102-cef3cfff-8b33-4b94-a39e-0a3d3c3d96d8.png){: width="70%" height="80%" .align-center}

Fast R-CNNì€ selective searchë¥¼ ì´ìš©í•œ 2ì²œê°œì˜ RoIë¥¼ ì‚¬ìš©í•œë‹¤. RoIëŠ” ì™œ í•˜í•„ 2ì²œê°œë¥¼ ì‚¬ìš©í• ê¹Œ? ë§ìœ¼ë©´ ë§ì„ ìˆ˜ë¡ ì¢‹ì„ê¹Œ? ìœ„ ê·¸ë˜í”„ëŠ” SS (selective search), Dense (DPM) ë‘ ë°©ì‹ì„ ì´ìš©í•´ RoI ê°¯ìˆ˜ë¥¼ ê³„ì† ëŠ˜ë¦° ê²°ê³¼ì´ë‹¤. RoIë¥¼ ë§‰ ë˜ì§€ê¸° ë•Œë¬¸ì— recallì„±ëŠ¥ì€ ì˜¬ë¼ê°€ì§€ë§Œ mAPì„±ëŠ¥ì€ ì–´ëŠì •ë„ ì˜¬ë¼ê°€ë‹¤ê°€ ë–¨ì–´ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ RoIëŠ” ë¬´ì¡°ê±´ ë§ë‹¤ê³  ì¢‹ì€ ê²ƒì´ ì•„ë‹ˆë‹¤.





<br>
<br>



[ë§¨ ìœ„ë¡œ ì´ë™í•˜ê¸°](#){: .btn .btn--primary }{: .align-right}