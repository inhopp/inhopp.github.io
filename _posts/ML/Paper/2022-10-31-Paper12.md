---
title:  "[논문 리뷰] YOLOv3 : An Incremental Improvement" 

categories:
  -  Paper
tags:
  - [ML, Object Detection]

toc: true
toc_sticky: true

date: 2022-10-31
last_modified_at: 2022-10-31
---

**Paper: <br>- [YOLOv3 : An Incremental Improvement](https://github.com/inhopp/inhopp/files/9896341/yolo_v3.pdf) <br>Reference: <br>- [PR-207: YOLOv3: An Incremental Improvement](https://www.youtube.com/watch?v=HMgcvgRrDcA)**
{: .notice--primary}


<br>

# 🚀 Introduction

![result](https://user-images.githubusercontent.com/96368476/198892154-8928dc6f-720a-4da0-8683-ae36178799ca.png){: width="40%" height="50%" .align-center}

저자는 지난 1년 동안 트위터와, GAN을 가지고 놀며 많은 시간을 보냈다고 한다. 또한 아주 흥미로운 내용이랄 것이 없고, 기존의 yolo 모델을 개선시킨 정도라고 솔직하게 말한다. 논문을 읽어보면 블로그 글을 읽는다는 느낌이 들고, 구성도 조금 특이해서 내가 편한 대로 재구성했다. YOLO v2 논문도 포스팅하려 했는데, 모델의 변화는 없고 전/후처리만 개선한 정도라 생략했다. YOLOv2에 등장한 테크닉들도 본 포스팅에 포함할 예정이다. 아무튼 결과만 미리 말하자면 yolo v2이후에 등장한 detection 모델인 SSD, RetinaNet과 비슷한 mAP를 달성하면서도 약 3배 정도 빠르다고 한다.


<br>


# 🚀 Model Architecture 

![architecture](https://user-images.githubusercontent.com/96368476/198893210-a077be70-2105-4bbf-a6ae-d75e5a539a6a.png){: width="40%" height="50%" .align-center}

YOLOv3의 가장 큰 특징은 prediction을 3번 진행한다는 것이다. 기존 yolo모델은 이미지 전체에 대해서 총 98개의 bbox만을 예측한다. 따라서 inference 속도는 빠르지만, bbox의 정확도가 많이 떨어진다는 한계가 있었다. YOLOv3에서는 Feature Pyramid Network(FPN)의 아이디어를 도입했다. 보통 CNN에서 conv + pooling layer를 거치면 더 높은 차원의 feature를 뽑아낼 수 있지만 동시에 위치 정보에 대한 손실이 발생한다. FPN의 핵심 아이디어는 여러 번의 conv + pooling layer 이후 생성된 최종 output(고차원의 feature)도 이용하고, 위치 정보를 덜 손실한 이전 layer들의 output들도 이용하는 것이다. YOLOv3에서는 feature extractor를 거친 후 생성된 19x19 image에서 prediction을 수행, (upsample + feature extractor의 이전 layer ouput) 38x38에서 다시 prediction을 수행한다. 이런 방식으로 총 3번의 prediction을 수행하게 된다.

<br>


![output](https://user-images.githubusercontent.com/96368476/198977572-788476a6-187e-4eb3-bd38-23458060ffed.png){: width="40%" height="50%" .align-center}

Prediction을 수행할 때 각 grid cell마다 3개의 bbox를 예측하게 된다. YOLOv1에서 총 98개의 bbox에 대해 예측을 했던 반면, YOLOv3에서는 총 10647개의 bbox에 대한 예측을 수행한다. 기존의 YOLO 모델은 빠르지만 적은 수의 bbox에 대한 예측으로 recall 성능이 많이 떨어진다는 단점이 있었는데, version3 에서 이 문제를 해결한 것이다.


<br>


# 🚀 Anchor Box Prediction

![bbox_clustering](https://user-images.githubusercontent.com/96368476/198940735-4711a249-89a3-4bd6-a4f3-b0a50ba0eee8.png){: width="70%" height="80%" .align-center}

Bounding boxes with dimension clustering은 YOLOv2에서 도입된 기법이다. 해당 기법은 bounding box의 초기 세팅값을 ground truth 값의 k-means clustering으로 정하는 것이다. 본 논문에서 COCO dataset을 사용해 구한 9개의 cluster값은 다음과 같다.

- 첫 번째 prediction에서 사용 : (10x13), (16x30), (33x23)
- 두 번째 prediction에서 사용 : (30×61), (62×45), (59× 119)
- 세 번째 prediction에서 사용 : (116 × 90), (156 × 198), (373 × 326)





<br>
<br>



[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}