---
title:  "[논문 리뷰] Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition (SPPnet)" 

categories:
  -  Paper
tags:
  - [Object Detection, ML]

toc: true
toc_sticky: true

date: 2022-03-05
last_modified_at: 2022-03-05
---

**Paper: <br>- [Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition](https://github.com/inhopp/inhopp/files/8190734/SPP.Net.pdf)**
{: .notice--primary}


<br>

# 🚀 Introduction

Object Detection 모델들은 대개 CNN을 기반으로 만들어졌다. 관련된 논문을 읽다보면 단순한 CNN 구조가 아닌 **'Feature Pyramid Network'** 구조를 사용했다는 말이 등장하는데, 이는 단순 CNN이 위치에 불변하기 때문이다(Location Invariant).
<br>

![1](https://user-images.githubusercontent.com/96368476/156887676-a19dc538-8488-460a-9516-7c9180227a2c.png){: .align-center}

분류를 위한 단순 CNN 구조를 생각해보자. 우선 Convolution과 Pooling을 이용해 input image의 특징을 뽑아낸다. 그 후 마지막 convolution 결과를 쭉 펴서 Fully Connected Layer에 집어 넣는다. FC layer는 뽑아낸 feature 값들을 바탕으로 이미지가 어떤 object인지 판단한다. 여기서 중요한 점은 분류기(FC layer)에 들어가는 input(마지막 convolution 결과값)이 위치에 불변하다는 것이다. 즉, object가 왼쪽 위 모서리에 존재하던 오른쪽 아래 모서리에 존재하던 마지막 convoltion 결과는 같은 feature값을 뽑을 것이다.

<br>

![5](https://user-images.githubusercontent.com/96368476/154627009-cf83638e-48b1-423f-94c7-e32ece00371d.png){: width="50%" height="60%" .align-center}

이 같은 현상이 나타나는 이유는 Pooling 때문인데, convolution layer가 깊어질 수록 더 넓은 영역을 커버하기 때문이다. 예를 들어 마지막 convolution layer에 눈을 탐지하는 필터가 있다고 해보자. 이 필터는 input 이미지의 굉장히 넓은 영역에서 눈이 있을 확률을 계산할 것이다.

<br>

![4](https://user-images.githubusercontent.com/96368476/155002334-51faba53-560e-4bd4-9c3c-52621c5949af.png){: width="60%" height="70%" .align-center}

따라서 object의 특징뿐만이 아닌 위치도 중요한 경우 pooling 중간중간의 feature map 들을 활용할 수 있다. 이렇듯 피라미드 모양으로 feature map 들을 쌓은 후 분류기(FC layer)에 넣어주는 방법을 Feature Pyramid Network라 한다. <br>

본 논문 SPP-net (Spatial Pyramid pooling - Network)은 이러한 아이디어를 처음으로 CNN에 적용시킨 모델이다. 앞서 살펴본 바와 같이 SPP-net은 하나의 모델로 바라보기 보다는 다른 모델에 장착하는 최적화 도구라고 보는 것이 맞다. 따라서 이번 포스팅에서 SPP-net의 구체적인 구조나 퍼포먼스는 과감하게 제외했다. 대신 모델이 등장하게 된 배경 (Motivation)과 이전의 어떤 모델에서 영감을 받았는지 등 아이디어를 위주로 살펴보고자 한다.



<br>

# 🚀 Motivation - CNN의 한계

CNN을 이용한 Vision task(classification, object detection, ...) 접근은 대체로 성공적이었다. 하지만 CNN에도 기술적인 이슈가 있었는데, 바로 고정된 input size를 요구한다는 것이었다. Input image들은 저마다의 크기와 비율이 존재하는데 이를 고정된 사이즈로 변경시키는 것은 누가 봐도 문제가 있어 보인다. 

![2](https://user-images.githubusercontent.com/96368476/156889187-178e5c3f-fc78-4dff-b62c-2cd972ea853f.png){: width="60%" height="70%" .align-center}

기존의 방식은 단순히 잘라버리던가(crop) 비율을 무시한 채 resize(warp) 하는 방식이었다. Cropping의 경우 잘린 이미지에 전체 object가 포함되지 않을 수 있고, Warping의 경우 공간적인 왜곡이 발생한다. 즉, pre-defined scale (ex. 224 x 224)은 다양한 input size에 적합하지 않다. 그럼에도 우리는 고정된 input size를 타협할 수밖에 없었다.

<br>

## CNN은 왜 fixed input size를 요구하나?

![1](https://user-images.githubusercontent.com/96368476/156887676-a19dc538-8488-460a-9516-7c9180227a2c.png){: .align-center}

CNN은 크게 Convolution Layer, Fully Connected Layer 두 파트로 나눌 수 있다. 이때 convolution의 과정을 생각해보면 fixed input size를 요구하지 않는다는 것을 알 수 있다. 아무 사이즈가 들어와도 convolution은 가능하다. 즉, fixed input size를 요구하는 범인은 CNN 저 끝에 있는 FC layer다. 

<br>

![3](https://user-images.githubusercontent.com/96368476/156889701-c27d4f72-9b04-4b82-b5cd-b0007176c09a.png){: width="60%" height="70%" .align-center}

본 논문의 아이디어는 convolution 까지는 input size에 상관없이 하자는 것이다. Convolution layer와 FC layer 사이에 새로운 layer 하나만 추가하면 된다. 이때 새로운 layer는 input size는 다양하게 받을 수 있지만 고정된 output size를 뱉어야 한다. 우리는 이 layer를 spatial pyramid pooling layer라 부르며, 전체 네트워크 구조를 SPP-net이라 부른다.



<br>

# 🚀 SPP-net 출생 배경

2015년 등장한 SPP-net의 저자들이 영감을 받은 모델은 Neural Network를 사용하지 않는 Object Detection 모델이다. CNN을 사용하지 않는 모델이라 하니 굉장히 구식처럼 느껴지는데, SPP-net은 결국 이미 사용하던 핵심 아이디어를 CNN버전으로 확장시킨 것이다. Vision 분야의 조상님들은 어떻게 Object Detection을 진행했는지 알아보자.

<br>

## Bag of Visual Words

![4](https://user-images.githubusercontent.com/96368476/156890727-2083560a-69f2-48b5-aabb-c98dd37a32fd.png){: width="60%" height="70%" .align-center}

- 이미지 데이터들을 잘게 쪼개 패치들을 만든다. 
- 모든 패치들을 사용할 수는 없으니 k-means clustering을 통해 주요 패치들을 뽑아낸다.
- 패치들의 히스토그램을 바탕으로 이미지를 분류한다.
- (조금 투박하지만 나름 CNN과 비슷하다.)


<br>

## Spatial Pyramid Matching (SPM)

![5](https://user-images.githubusercontent.com/96368476/156891106-2d6c6e73-fbd3-40c3-b58e-c5a359e5a64e.png){: width="60%" height="70%" .align-center}

- Bag of visual words 방식도 Simple CNN과 같이 위치를 특정할 수 없다.
- 위치 정보를 주기 위해 이미지를 층별로 다르게 분할하고, 분할된 영역에서 Bag of visual words 히스토그램을 계산한다.

<br>

![6](https://user-images.githubusercontent.com/96368476/156891503-1c71190e-ba40-4ac5-ae93-a59f3c8c60f7.png){: width="60%" height="70%" .align-center}

- 각 영역별로 max-pooling 적용 후 Flatten
- 벡터값 이어 붙이기
- **<span style="color:red">output data의 size는 input size가 아닌 분할 방식에 의해 결정된다 → 내가 정할 수 있다!</span>**


<br>

## Spatial Pyramid Pooling (SPP)

![7](https://user-images.githubusercontent.com/96368476/156891789-9b60fbb9-0f33-46c6-91ad-9f866b27e18d.png){: width="60%" height="70%" .align-center}

- SPP는 SPM에 영감을 받아 각 feature map을 원하는 사이즈로 pooling
- pooling 결과값을 이어 붙이면 input size에 상관없이 고정된 output size 생성 가능!



<br>

# 🚀 Spatial Pyramid Pooling(SPP) 특징

SPP를 적용한 네트워크는 다음과 같은 장점이 있다.
- 다양한 input size를 받으면 모델의 성능이 좋아진다.
  - 크기와 상관없이 object를 구별하게 훈련시킬 수 있다. (increasing scale-invariance)
  - 동일한 image의 사이즈를 변경시켜가며 훈련시킬 수 있다. (decreasing overfitting)
- Convolution의 최종 결과 feature vector가 object의 위치 정보도 가지고 있다.
- CNN 구조와 관계없이 적용할 수 있다.
  - ex) AlexNet, VGG, GoogleNet, ResNet, ... 에 모두 적용 가능

<br>

## SPP의 한계

**저자들의 계획은 완벽했다. 이론적으로는...** <br>

![8](https://user-images.githubusercontent.com/96368476/156893242-9f1b5dea-8b6c-42c8-851e-b4e9f8f12bb1.jpeg){: width="30%" height="40%" .align-center}

**<span style="color:red">문제는 하드웨어에 있었다.</span>** 이론상으로 input size와 상관없이 convolution할 수 있다. 하지만 그때그때 convolution size가 달라지면 GPU가 매우 비효율적으로 작동하게 된다. 분명 합리적인 접근이었지만 예상치 못한 하드웨어 이슈로 사장될 위기에 처했다. SPP-net은 어떻게 부활했을까?



<br>

# 🚀 SPP-net 부활

결국 SPP-net의 장점 중 써먹을 수 있는 것은 Convolution 후에도 object의 위치 정보를 가지고 있다는 것뿐이다. 저자들은 이를 이용해 새로운 object detection 모델을 제안했는데 생각보다 효과가 너무 좋았다. 2015년 당시의 object detection 모델 R-CNN을 살펴보자.

<br>

## R-CNN 구조

**[R-CNN 논문 리뷰](https://inhopp.github.io/paper/Paper3/)**
{: .notice--success}

![9](https://user-images.githubusercontent.com/96368476/156893828-9ab8ac4f-0d51-4cb3-b632-d83f68c4ee1c.png){: width="50%" height="60%" .align-center}

기존의 R-CNN 모델은 수많은 영역을 제안받은 후 각 영역별로 convolution을 시행한다. 이때 각 영역별로 사용되는 convolution network는 파라미터를 공유하는 동일한 네트워크 이다. 즉, 하나의 이미지 안에서 동일한 연산을 반복하는 비효율적인 구조이다. Region proposal 이전에 convolution을 먼저 하면 좋겠지만 그렇게 할 수 없는 이유는 지금까지 계속 언급한 바와 같다. Convolution을 먼저 해버리면 object의 위치 정보를 잊어버리기 때문이다. 


<br>

## R-CNN with SPP

![10](https://user-images.githubusercontent.com/96368476/156894301-4d0c08e1-345a-46c9-89f7-500c528d35a0.png){: width="60%" height="70%" .align-center}

- SPP를 이용한 convolution은 위치 정보를 유지하기 때문에 convolution 먼저 해도 괜찮다!
- 먼저 전체 이미지 convolution, 그 다음 region proposal
- **<span style="color:red">낭비되는 convolution 연산 없음 & 훨씬 작은 output size에서 region proposal</span>**
- Region proposal 이후 CNN은 FC layer 같은 아주 단순한 구조 (이미 특징들을 뽑아놓았기 때문에)
- 최대 102배까지 속도가 빨라지더라!


<br>

# 🚀 개인적인 느낀점

사실 SPP 구조는 Object Detection 분야에서 사용되는 하나의 테크닉 정도로만 알고있었다. 이해하기 어려운 내용도 아니라서 굳이 논문까지 읽어야 하나 싶었는데, 특이한 논문이어서 읽어보길 잘한 것 같다. 내가 느끼기에 이 논문의 기승전결 중 절정은 하드웨어 이슈 부분이다. 결국 저자들이 해결하고자 하는 문제 (Motivation : 다양한 Input size를 훈련시키고 싶다)는 해결하지 못하고 다른 흐름으로 이야기가 전개된다. 논문을 많이 읽어보진 않았지만 이런 논문은 처음 봤다. 여타 논문들과는 다른 의미로? 굉장히 재밌는 논문이었다. 근데 다른 사람들의 자료를 찾아보니 하드웨어 이슈를 언급한 자료가 하나도 없었다. 아무도 없으니 나만 느낀 즐거움인지, 내가 잘 못 이해한 것인지 조금 헷갈린다. 같이 공부하는 친구가 생기면 좋을 것 같다.



<br>
<br>

[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}