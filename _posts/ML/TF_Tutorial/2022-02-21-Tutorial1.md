---
title:  "[TF_Tutorial] MoveNet - Pose Detection" 

categories:
  -  TF_Tutorial
tags:
  - [ML, tutorial]

toc: true
toc_sticky: true

date: 2022-02-21
last_modified_at: 2022-02-21
---

**Main Reference: <br>- [TensorFlow Blog : MoveNet](https://blog.tensorflow.org/2021/05/next-generation-pose-detection-with-movenet-and-tensorflowjs.html) <br>- [An Overview of Human Pose Estimation with Deep Learning](https://beyondminds.ai/blog/an-overview-of-human-pose-estimation-with-deep-learning/#:~:text=Multi%2DPerson%20Pose%20Estimation&text=This%20method%20is%20known%20as,as%20the%20bottom%2Dup%20approach)** 
{: .notice--warning}


<br>


# ğŸš¤ Pose Detection ì´ë€?

| Input | Pose Detection |
|:-:|:-:|
|![dance_input](https://user-images.githubusercontent.com/96368476/154976986-d4346ce1-3934-4c30-9dda-d343364180ee.gif)|![dance](https://user-images.githubusercontent.com/96368476/154977022-98f057eb-b35a-4bc2-9071-4e76af39e11d.gif)|

<br>

Pose Detectionì€ íŠ¹ì • ì‹ ì²´ ë¶€ìœ„(ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©, ë“±ë“±..)ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ì—¬ ì‚¬ëŒì˜ í¬ì¦ˆë¥¼ íƒì§€í•˜ëŠ” ì‘ì—…ì´ë‹¤. MoveNetì€ ë¨¼ì € 17ê°œì˜ keypointsë¥¼ ì°¾ê³ , keypointsë¡œ edgeë¥¼ ë§Œë“¤ì–´ í¬ì¦ˆë¥¼ ì¶”ì •í•œë‹¤. <br> **[ì½”, ëˆˆ, ê·€, ì–´ê¹¨, íŒ”ê¿ˆì¹˜, ì†ëª©, ì—‰ë©ì´, ë¬´ë¦, ë°œëª©]** - ì½”ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë¶€ìœ„ëŠ” ì™¼ìª½, ì˜¤ë¥¸ìª½ x2

<br>

## MoveNet

Pose Detectionì€ ì§€ë‚œ ëª‡ ë…„ ë§ì€ ë°œì „ì„ ì´ë£¨ì—ˆì§€ë§Œ, ì‘ìš© ë‹¨ê³„ê¹Œì§€ ë‚˜ì•„ê°€ì§€ ëª»í–ˆë‹¤. ëª¨ë¸ì˜ í¼í¬ë¨¼ìŠ¤(ì •í™•ë„&ì†ë„)ê°€ ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤. MoveNet ëª¨ë¸ì€ ì´ì „ ëª¨ë¸ì¸ PoseNetì˜ ì„±ëŠ¥ì„ ëŠ¥ê°€í•˜ë©° íŠ¹íˆ ì†ë„ ì¸¡ë©´ì—ì„œ ì—„ì²­ë‚œ ìµœì í™”ë¥¼ ì´ë£¨ì—ˆë‹¤(Ultra fast modelì´ë¼ê³  ì†Œê°œí•œë‹¤). MoveNetì€ ë‘ ê°€ì§€ ë²„ì „ì´ ì¡´ì¬í•˜ëŠ”ë°, ì†ë„ì— ì¤‘ì ì„ ë‘” MoveNet_Lightning ë²„ì „ì˜ ê²½ìš° ëª¨ë°”ì¼ í™˜ê²½ì—ì„œë„ real-time ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤.

- **MoveNet_Lightning** : Thunderëª¨ë¸ì— ë¹„í•´ ì •í™•ë„ëŠ” ë–¨ì–´ì§€ì§€ë§Œ, ì´ˆë‹¹ 50í”„ë ˆì„ ì´ìƒ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ê³  ë‚´ì¥ ê·¸ë˜í”½ì¹´ë“œë¥¼ ì“°ëŠ” ë…¸íŠ¸ë¶ì´ë‚˜ ëª¨ë°”ì¼ í™˜ê²½ì—ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.
- **MoveNet_Thunder** : Lightning ëª¨ë¸ì— ë¹„í•´ í¬ê³  ëŠë¦¬ì§€ë§Œ, ë†’ì€ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤€ë‹¤. (ê·¸ëŸ¼ì—ë„ ì´ˆë‹¹ 30í”„ë ˆì„ ì´ìƒ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë‹¤.)


<br>


# ğŸš¤ Model Architecture

![2](https://user-images.githubusercontent.com/96368476/154998888-6caa01f0-5690-455e-a19c-382e5ac60713.png){: width="70%" height="80%" .align-center}

ì—¬ëŠ detector ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ MoveNet ì—­ì‹œ feature extraction + prediction (2 stage) êµ¬ì¡°ë¥¼ ì´ë£¨ê³  ìˆë‹¤. ì´ë•Œ feature extractorëŠ” FPN(feature pyramid network)ì´ ë¶€ì°©ëœ MobileNetV2ë¥¼ ì‚¬ìš©í•˜ê³ , predictionì€ 4ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤.

<br>

## Feature Pyramid Networkë€?

![3](https://user-images.githubusercontent.com/96368476/154999995-32545be5-1ec3-422f-8dac-7751482bbb13.png){: .align-center}

Classificationì„ ìœ„í•œ ë‹¨ìˆœí•œ CNNì„ ìƒê°í•´ë³´ì. ì´ë•Œ convolitionì€ object ìœ„ì¹˜ì— í¬ê²Œ ìƒê´€í•˜ì§€ ì•ŠëŠ”ë‹¤. ì¦‰, ê³ ì–‘ì´ê°€ ì‚¬ì§„ ì™¼ìª½ì— ìˆë“  ì˜¤ë¥¸ìª½ì— ìˆë“  CNN ëª¨ë¸ì€ ê³ ì–‘ì´ë¥¼ outputìœ¼ë¡œ ë±‰ì„ ê²ƒì´ë‹¤.

<br>

![4](https://user-images.githubusercontent.com/96368476/155002334-51faba53-560e-4bd4-9c3c-52621c5949af.png){: width="60%" height="70%" .align-center}

ë”°ë¼ì„œ objectì˜ ìœ„ì¹˜ì— ë¯¼ê°í•œ ê²½ìš° convolutionì´ ë‹¤ ëë‚˜ê³  ë§ˆì§€ë§‰ì— ë‚˜ì˜¤ëŠ” feature vector ë¿ë§Œì´ ì•„ë‹ˆë¼ convolution ì¤‘ê°„ì¤‘ê°„ì˜ feature map ë“¤ë„ í™œìš©í•  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë°©ë²•ì„ feature pyramid networkë¼ í•œë‹¤.


<br>


## Prediction

![5](https://user-images.githubusercontent.com/96368476/155003833-9c6bec5a-aff4-4849-8a6f-b7e795d3b530.png){: .align-center}

MoveNetì˜ Prediction headëŠ” 4 íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê°ê°ì˜ ì˜ˆì¸¡ì€ ë‹¤ìŒ sequence ì‘ì—…ì„ ë”°ë¥¸ë‹¤.

- step1 : Person center heat map
  - ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì¤‘ì‹¬ì„ ì‹ë³„í•œë‹¤. ì´ ì¤‘ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìœ„ì¹˜ê°€ ì„ íƒëœë‹¤.
- step2 : Keypoint regression field
  - ì„ íƒëœ ì¤‘ì‹¬ í”½ì…€ì„ ê¸°ì¤€ìœ¼ë¡œ keypoints ì˜ ì´ˆê¸°ê°’ì„ ìƒì„±í•œë‹¤. ì´ëŠ” roughí•œ ê°’ìœ¼ë¡œ ì •í™•ë„ê°€ ë§ì´ ë–¨ì–´ì§„ë‹¤.
- step3 : Person keypoint heatmap
  - step2ì˜ ì´ˆê¸°ê°’ìœ¼ë¡œë¶€í„° ê±°ë¦¬ì— ë°˜ë¹„ë¡€í•˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì´ìš©í•´ heatmapì„ ë§Œë“ ë‹¤ (ê° keypoint ë§ˆë‹¤)
- step4 : 2D per-keypoint offset field
  - fine tuning


<br>


## ìƒí–¥ì‹ ì¶”ì • vs í•˜í–¥ì‹ ì¶”ì •

> ì œê°€ ì´í•´í•˜ê¸°ì— ì´ ë¶€ë¶„ì€ ìœ„ ë‚´ìš©ê³¼ ìƒì¶©í•©ë‹ˆë‹¤. <br>ì‚¬ëŒì˜ ì¤‘ì‹¬(Person center heat map)ì„ ì°¾ì€ í›„ í•´ë‹¹ í”½ì…€ì„ ê¸°ì¤€ìœ¼ë¡œ keypointsë¥¼ ì°¾ìœ¼ë‹ˆ top-down ë°©ì‹ì´ë¼ê³  ìƒê°ë©ë‹ˆë‹¤. <br>TensorFlow ë¸”ë¡œê·¸ì— ìˆëŠ” ë‚´ìš©ì´ë¼ ì¼ë‹¨ ì‘ì„±í–ˆì§€ë§Œ, ì €ëŠ” ì•„ì§ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

![1](https://user-images.githubusercontent.com/96368476/154995885-3f6fb803-4a76-40d4-92df-c97921589ecf.png){: width="60%" height="70%" .align-center}

- top-down (í•˜í–¥ì‹) : person detect ë¨¼ì € â†’ Pose ì¶”ì •
- bottom-up (ìƒí–¥ì‹) : keypoints detect â†’ grouping

ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ëŒì„ ë¨¼ì € íƒì§€í•˜ê³  ê·¸ ì•ˆì—ì„œ í¬ì¦ˆë¥¼ ì¶”ì •í•˜ëŠ” í•˜í–¥ì‹ ë°©ë²•ì´ ë” ê°„ë‹¨í•˜ë‹¤. í•˜ì§€ë§Œ MoveNetì˜ ê²½ìš° ìƒí–¥ì‹ ë°©ë²•ì„ ì´ìš©í•œ SinglePose Detector(í•œ ì‚¬ëŒë§Œ íƒì§€) ì´ë‹¤.
êµ³ì´ ì´ëŸ° ë°©ì‹ì„ íƒí•œ ì´ìœ ëŠ” ë¹„ë””ì˜¤ì—ì„œì˜ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ì„œì´ë‹¤. ê°„ë‹¨íˆ ë§í•´ ì´ì „ í”„ë ˆì„ì—ì„œ í¬ì¦ˆê°€ ê°ì§€ëœ ì˜ì—­ì„ ì°¸ê³ í•˜ì—¬ í˜„ì¬ í”„ë ˆì„ í¬ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì´ë‹¤.





<br>


# ğŸš¤ Datasets

ëª¨ë¸ Trainingì—ëŠ” COCO Datasetê³¼ Google ë‚´ë¶€ì— ì¡´ì¬í•˜ëŠ” Active Dataset ì„ ì´ìš©í–ˆë‹¤. COCO dasetì˜ ê²½ìš° object detection, segmantation ë“± ì¼ë°˜ì ì¸ Computer Vision ì‘ì—…ì„ ìœ„í•´ ë§Œë“¤ì–´ì§„ ë°ì´í„°ì´ë‹¤. ë”°ë¼ì„œ êµ¬ê¸€ì—ì„œëŠ” Pose Detectionë§Œì„ ìœ„í•œ Active Datasetì„ ë§Œë“¤ì–´ í›ˆë ¨ì‹œì¼°ë‹¤. Active Datasetì€ ìœ íŠœë¸Œì— ì¡´ì¬í•˜ëŠ” ì˜ìƒ ì¤‘ ìš”ê°€, ìš´ë™, ì¶¤ ë“±ì„ ìº¡ì³í•œ dataset ì´ë‹¤.

<br>


![7](https://user-images.githubusercontent.com/96368476/155008114-394facf4-820a-4262-8f16-b051765e1c89.png){: width="60%" height="70%" .align-center}


<br>


# ğŸš¤ Performance

## Accuracy

![8](https://user-images.githubusercontent.com/96368476/155009481-987de0cc-f533-4092-a401-a2c2d87817a1.png){: width="80%" height="90%" .align-center}

- ì„ì˜ì˜ ì´ë¯¸ì§€ì¸ COCO Datasetì—ì„œëŠ” ì„±ëŠ¥ì´ ì¡°ê¸ˆ ë–¨ì–´ì§€ì§€ë§Œ Active Datasetì—ì„œëŠ” ìƒë‹¹íˆ ë†’ì€ mAPë¥¼ ë³´ì—¬ì¤€ë‹¤.

<br>

## Speed

![9](https://user-images.githubusercontent.com/96368476/155009484-2f1a3df6-6a40-4d80-a872-5d2b971848a7.png)

- ë‚´ì¥ê·¸ë˜í”½ë§Œìœ¼ë¡œë„ ìƒë‹¹íˆ ë¹ ë¥¸ ì†ë„ë¥¼ ë³´ì—¬ì¤€ë‹¤.


<br>


# ğŸš¤ ì‹¤ìŠµ ì½”ë“œ

**[TensorFlow Tutoral Code](https://www.tensorflow.org/hub/tutorials/movenet) : real-time ë°ëª¨ ì¡´ì¬**
{: .notice--primary}

ì°¸ê³ ) ì¹´ë©”ë¼ë¡œë¶€í„° 3í”¼íŠ¸ ~ 6í”¼íŠ¸ê°€ ê°€ì¥ ì¢‹ë‹¤ê³  í•œë‹¤.


## Lightningì„ ì´ìš©í•œ real-time detection

> ê²°ê³¼ì ìœ¼ë¡œ colabì—ì„œ real-time testëŠ” ì‹¤íŒ¨í–ˆë‹¤.<br>colabì´ virtural machine í™˜ê²½ì´ë¼ ë…¸íŠ¸ë¶ ì¹´ë©”ë¼ì— ì ‘ê·¼(cv2.VideoCaputre(0))ì„ ëª»í•˜ë”ë¼.<br>js ì´ìš©í•´ì„œ ì¹´ë©”ë¼ë¥¼ í‚¤ëŠ” ë°©ë²•ì€ ì°¾ì•˜ì§€ë§Œ real-time + í”„ë ˆì„ë³„ë¡œ ìª¼ê°œì„œ detecting í•˜ëŠ”ë° ì‹¤íŒ¨í–ˆë‹¤. colab ì“°ë©´ì„œ ì²˜ìŒìœ¼ë¡œ í™”ë‚¬ë‹¤<br>ì•„ë¬´íŠ¼ real-timeì€ ì‹¤íŒ¨í•˜ê³  ë…¹í™” ì˜ìƒìœ¼ë¡œ ëŒ€ì²´.

**[Tutoral Code_lightning](https://github.com/inhopp/ML_code/blob/main/MoveNet_lightning.ipynb)**
{: .notice--primary}

![1111](https://user-images.githubusercontent.com/96368476/155013161-2922854a-18c1-4ff7-81f6-50eb7ac42230.gif){: width="70%" height="80%" .align-center}

<br>

## Thunderë¥¼ ì´ìš©í•œ ë®¤ì§ë¹„ë””ì˜¤ ì˜ìƒ detection

**[Tutoral Code_thunder](https://github.com/inhopp/ML_code/blob/main/MoveNet_thunder.ipynb)**
{: .notice--primary}

| Input | Pose Detection |
|:-:|:-:|
|![1233](https://user-images.githubusercontent.com/96368476/155010552-b08a59b2-6ff5-4095-b451-7bf40200c1ab.gif)|![1234](https://user-images.githubusercontent.com/96368476/155010726-62f8e52a-d415-449f-a0bb-738172eba350.gif)|


<br>
<br>

[ë§¨ ìœ„ë¡œ ì´ë™í•˜ê¸°](#){: .btn .btn--primary }{: .align-right}