---
title:  "[TF_Tutorial] On-device Real-time Hand Tracking" 

categories:
  -  TF_Tutorial
tags:
  - [ML, tutorial]

toc: true
toc_sticky: true

date: 2022-02-28
last_modified_at: 2022-02-28
---

**Main Reference: <br>- [TensorFlow Blog : 3D Hand Pose with MediaPipe and TensorFlow.js](https://blog.tensorflow.org/2021/11/3D-handpose.html) <br>- [Google AI Blog : On-Device, Real-Time Hand Tracking with MediaPipe](https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html) <br>- [MediaPipe - Hands](https://google.github.io/mediapipe/solutions/hands.html)** 
{: .notice--warning}



**Paper: <br>- [MediaPipe Hands: On-device Real-time Hand Tracking](https://github.com/inhopp/inhopp/files/8153383/MediaPipe.Hands._.On-device.Real-time.Hand.Tracking.pdf)**
{: .notice--primary}


<br>


# 🚤 Introduction

|Example1|Example2|
|:-:|:-:|
|![2](https://user-images.githubusercontent.com/96368476/155987751-499a3007-1343-4962-9f9a-2a5894795474.gif)|![1](https://user-images.githubusercontent.com/96368476/155987674-c5bf968d-ae33-4b37-a887-a069a9a31fb1.gif)|

![4](https://user-images.githubusercontent.com/96368476/155989618-6187c2e9-0ef9-4a92-87db-5187443d06cc.gif){: width="70%" height="80%" .align-center}

Hand Tracking 기술은 기계의 제스처 제어, 수화 이해 등 여러 플랫폼에서 중요한 구성 요소가 될 수 있다. 특히 실제 세계의 정보와 디지털 정보가 겹쳐지는 VR/AR 분야에서는 핵심적인 기술이다. 기존의 Hand Tracking 모델들은 손에 장비를 착용하거나, 특수한 카메라를 사용하거나 하는 하드웨어에 의존적인 방식이었다. 우리가 제안하는 모델은 다음과 같은 장점이 있다.
- 카메라 이외에 추가적인 하드웨어는 필요없다.
- 2개 이상의 손도 탐지할 수 있고, 손의 일부가 가려지더라도 탐지된다.
- 모바일 환경에서 실시간 연산이 가능하다.


<br>


# 🚤 Model Architecture

본 모델은 2 stage Detector 구조를 이루고 있다.

1. Bounding box를 찾는 손바닥 Detector
2. 각 Bounding box(손) 별로 20개의 keypoints 탐지
  - ![5](https://user-images.githubusercontent.com/96368476/155993065-f1b57661-3601-4d9b-9625-92584ab680a7.png){: width="70%" height="80%" .align-center}


<br>

## Palm Detector (손바닥 탐지)



<br>
<br>

[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}